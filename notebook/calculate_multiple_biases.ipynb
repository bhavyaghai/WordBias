{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./word2vec.csv\",header=0, keep_default_na=False)\n",
    "#df = pd.read_csv(\"./word2vec_debiased.csv\",header=0, keep_default_na=False)\n",
    "path = \"../data/word_embeddings/\"\n",
    "model =  word2vec.KeyedVectors.load_word2vec_format(path+'word2vec_50k.bin', binary=True)\n",
    "#model =  word2vec.KeyedVectors.load_word2vec_format(path+'glove_50k.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word\n",
       "0    in\n",
       "1   for\n",
       "2  that\n",
       "3    is\n",
       "4    on"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"word\":list(model.vocab.keys())})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate bias direction when we have group of words not pairs\n",
    "def groupBiasDirection(gp1, gp2):\n",
    "    #print(gp1,gp2)\n",
    "    dim = len(model[\"he\"])\n",
    "    g1,g2 = np.zeros((dim,), dtype=float), np.zeros((dim,), dtype=float)\n",
    "    cnt = 0\n",
    "    for p in gp1:\n",
    "        p = p.strip()\n",
    "        if p not in model:\n",
    "            continue\n",
    "        p_vec = model[p]/norm(model[p])\n",
    "        g1 = np.add(g1,p_vec)\n",
    "        cnt += 1\n",
    "    print(\"count:  \", cnt)\n",
    "\n",
    "    cnt = 0\n",
    "    for q in gp2:\n",
    "        q = q.strip()\n",
    "        if q not in model:\n",
    "            continue\n",
    "        q_vec = model[q]/norm(model[q])\n",
    "        g2 = np.add(g2,q_vec) \n",
    "        cnt += 1\n",
    "    print(\"count 2:  \", cnt)\n",
    "    g1, g2 = g1/norm(g1), g2/norm(g2)\n",
    "    return (g1,g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruth True\n",
      "William True\n",
      "Horace True\n",
      "Mary True\n",
      "Susie True\n",
      "Amy True\n",
      "John True\n",
      "Henry True\n",
      "Edward True\n",
      "Elizabeth True\n"
     ]
    }
   ],
   "source": [
    "#y = \"tiffany,michelle,cindy,kristy,brad,eric,joey,billy\".split(\",\")\n",
    "y = \"Ruth, William, Horace, Mary, Susie, Amy, John, Henry, Edward, Elizabeth\".split(\",\")\n",
    "for w in y:\n",
    "    w = w.strip()\n",
    "    print(w, w in model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias = [\"he, son, his, him, father, man, boy, himself, male, brother, sons, fathers, men, boys, males, brothers, uncle, uncles, nephew, nephews\".split(\",\"),\n",
    "               \"she, daughter, hers, her, mother, woman, girl, herself, female, sister, daughters, mothers, women, girls, femen, sisters, aunt, aunts, niece, nieces\".split(\",\")]\n",
    "#eco_bias = [(\"rich\",\"wealthy\"),(\"poor\",\"impoverished\")]\n",
    "race_bias = [\"Alonzo, Jamel, Lerone, Percell, Theo, Alphonse, Jerome, Leroy, Rasaan, Torrance, Darnell,Lamar, Lionel, Rashaun, Tvree, Deion, Lamont, Malik, Terrence, Tyrone, Everol, Lavon, Marcellus, Terryl, Wardell,Aiesha, Lashelle, Nichelle, Shereen, Temeka, Ebony, Latisha, Shaniqua, Tameisha, Teretha, Jasmine, Latonya, Shanise,Tanisha, Tia, Lakisha, Latoya, Sharise, Tashika, Yolanda, Lashandra, Malika, Shavonn, Tawanda, Yvette\".split(\",\"),\n",
    "             \"Adam, Chip, Harry, Josh, Roger, Alan, Frank, Ian, Justin, Ryan, Andrew, Fred, Jack,Matthew, Stephen, Brad, Greg, Jed, Paul, Todd, Brandon, Hank, Jonathan, Peter, Wilbur, Amanda, Courtney, Heather,Melanie, Sara, Amber, Crystal, Katie, Meredith, Shannon, Betsy, Donna, Kristin, Nancy, Stephanie, Bobbie-Sue, Ellen,Lauren, Peggy, Sue-Ellen, Colleen, Emily, Megan, Rachel, Wendy\".split(\",\")]\n",
    "\n",
    "religion_bias = [\"baptism, messiah, catholicism, resurrection, christianity, salvation, protestant, gospel, trinity, jesus, christ, christian, cross, catholic, church\".split(\",\"),\n",
    "                \"allah, ramadan, turban, emir, salaam, sunni, koran, imam, sultan, prophet, veil, ayatollah, shiite, mosque, islam, sheik, muslim, muhammad\".split(\",\")]\n",
    "\n",
    "#sentiment_bias = [\"caress, freedom, health, love, peace, cheer, friend, heaven, loyal, pleasure, diamond, gentle, honest, lucky, rainbow, diploma, gift, honor, miracle, sunrise, family, happy, laughter, paradise, vacation\".split(\",\"),\n",
    "#                 \"abuse, crash, filth, murder, sickness, accident, death, grief, poison, stink, assault, disaster, hatred, pollute, tragedy, divorce, jail, poverty, ugly, cancer, kill, rotten, vomit, agony, prison\".split(\",\")]\n",
    "\n",
    "age_bias = [\"Taylor, Jamie, Daniel, Aubrey, Alison, Miranda, Jacob, Arthur, Aaron, Ethan\".split(\",\"),\n",
    "           \"Ruth, William, Horace, Mary, Susie, Amy, John, Henry, Edward, Elizabeth\".split(\",\")]\n",
    "\n",
    "eco_bias = [\"rich,richer,richest,affluence,advantaged,wealthy,costly,exorbitant,expensive,exquisite,extravagant,flush,invaluable,lavish,luxuriant,luxurious,luxury,moneyed,opulent,plush,precious,priceless,privileged,prosperous,classy\".split(\",\"),\n",
    "           \"poor,poorer,poorest,poverty,destitude,needy,impoverished,economical,inexpensive,ruined,cheap,penurious,underprivileged,penniless,valueless,penury,indigence,bankrupt,beggarly,moneyless,insolvent\".split(\",\")]\n",
    "\n",
    "#bias_words = {\"gender\":gender_bias, \"religion\":religion_bias, \"race\":race_bias, \"age\":age_bias, \"sentiment\":sentiment_bias, \"economic\":eco_bias}\n",
    "bias_words = {\"gender\":gender_bias, \"religion\":religion_bias, \"race\":race_bias, \"age\":age_bias, \"economic\":eco_bias}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "femen\n",
      "Tvree\n",
      "Everol\n",
      "Teretha\n",
      "Shavonn\n",
      "Bobbie-Sue\n",
      "Sue-Ellen\n",
      "destitude\n"
     ]
    }
   ],
   "source": [
    "for bias_type in bias_words:\n",
    "    for words in bias_words[bias_type]:\n",
    "        for w in words:\n",
    "            w = w.strip()\n",
    "            if w not in model:\n",
    "                print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': [['he',\n",
       "   ' son',\n",
       "   ' his',\n",
       "   ' him',\n",
       "   ' father',\n",
       "   ' man',\n",
       "   ' boy',\n",
       "   ' himself',\n",
       "   ' male',\n",
       "   ' brother',\n",
       "   ' sons',\n",
       "   ' fathers',\n",
       "   ' men',\n",
       "   ' boys',\n",
       "   ' males',\n",
       "   ' brothers',\n",
       "   ' uncle',\n",
       "   ' uncles',\n",
       "   ' nephew',\n",
       "   ' nephews'],\n",
       "  ['she',\n",
       "   ' daughter',\n",
       "   ' hers',\n",
       "   ' her',\n",
       "   ' mother',\n",
       "   ' woman',\n",
       "   ' girl',\n",
       "   ' herself',\n",
       "   ' female',\n",
       "   ' sister',\n",
       "   ' daughters',\n",
       "   ' mothers',\n",
       "   ' women',\n",
       "   ' girls',\n",
       "   ' femen',\n",
       "   ' sisters',\n",
       "   ' aunt',\n",
       "   ' aunts',\n",
       "   ' niece',\n",
       "   ' nieces']],\n",
       " 'religion': [['baptism',\n",
       "   ' messiah',\n",
       "   ' catholicism',\n",
       "   ' resurrection',\n",
       "   ' christianity',\n",
       "   ' salvation',\n",
       "   ' protestant',\n",
       "   ' gospel',\n",
       "   ' trinity',\n",
       "   ' jesus',\n",
       "   ' christ',\n",
       "   ' christian',\n",
       "   ' cross',\n",
       "   ' catholic',\n",
       "   ' church'],\n",
       "  ['allah',\n",
       "   ' ramadan',\n",
       "   ' turban',\n",
       "   ' emir',\n",
       "   ' salaam',\n",
       "   ' sunni',\n",
       "   ' koran',\n",
       "   ' imam',\n",
       "   ' sultan',\n",
       "   ' prophet',\n",
       "   ' veil',\n",
       "   ' ayatollah',\n",
       "   ' shiite',\n",
       "   ' mosque',\n",
       "   ' islam',\n",
       "   ' sheik',\n",
       "   ' muslim',\n",
       "   ' muhammad']],\n",
       " 'race': [['Alonzo',\n",
       "   ' Jamel',\n",
       "   ' Lerone',\n",
       "   ' Percell',\n",
       "   ' Theo',\n",
       "   ' Alphonse',\n",
       "   ' Jerome',\n",
       "   ' Leroy',\n",
       "   ' Rasaan',\n",
       "   ' Torrance',\n",
       "   ' Darnell',\n",
       "   'Lamar',\n",
       "   ' Lionel',\n",
       "   ' Rashaun',\n",
       "   ' Tvree',\n",
       "   ' Deion',\n",
       "   ' Lamont',\n",
       "   ' Malik',\n",
       "   ' Terrence',\n",
       "   ' Tyrone',\n",
       "   ' Everol',\n",
       "   ' Lavon',\n",
       "   ' Marcellus',\n",
       "   ' Terryl',\n",
       "   ' Wardell',\n",
       "   'Aiesha',\n",
       "   ' Lashelle',\n",
       "   ' Nichelle',\n",
       "   ' Shereen',\n",
       "   ' Temeka',\n",
       "   ' Ebony',\n",
       "   ' Latisha',\n",
       "   ' Shaniqua',\n",
       "   ' Tameisha',\n",
       "   ' Teretha',\n",
       "   ' Jasmine',\n",
       "   ' Latonya',\n",
       "   ' Shanise',\n",
       "   'Tanisha',\n",
       "   ' Tia',\n",
       "   ' Lakisha',\n",
       "   ' Latoya',\n",
       "   ' Sharise',\n",
       "   ' Tashika',\n",
       "   ' Yolanda',\n",
       "   ' Lashandra',\n",
       "   ' Malika',\n",
       "   ' Shavonn',\n",
       "   ' Tawanda',\n",
       "   ' Yvette'],\n",
       "  ['Adam',\n",
       "   ' Chip',\n",
       "   ' Harry',\n",
       "   ' Josh',\n",
       "   ' Roger',\n",
       "   ' Alan',\n",
       "   ' Frank',\n",
       "   ' Ian',\n",
       "   ' Justin',\n",
       "   ' Ryan',\n",
       "   ' Andrew',\n",
       "   ' Fred',\n",
       "   ' Jack',\n",
       "   'Matthew',\n",
       "   ' Stephen',\n",
       "   ' Brad',\n",
       "   ' Greg',\n",
       "   ' Jed',\n",
       "   ' Paul',\n",
       "   ' Todd',\n",
       "   ' Brandon',\n",
       "   ' Hank',\n",
       "   ' Jonathan',\n",
       "   ' Peter',\n",
       "   ' Wilbur',\n",
       "   ' Amanda',\n",
       "   ' Courtney',\n",
       "   ' Heather',\n",
       "   'Melanie',\n",
       "   ' Sara',\n",
       "   ' Amber',\n",
       "   ' Crystal',\n",
       "   ' Katie',\n",
       "   ' Meredith',\n",
       "   ' Shannon',\n",
       "   ' Betsy',\n",
       "   ' Donna',\n",
       "   ' Kristin',\n",
       "   ' Nancy',\n",
       "   ' Stephanie',\n",
       "   ' Bobbie-Sue',\n",
       "   ' Ellen',\n",
       "   'Lauren',\n",
       "   ' Peggy',\n",
       "   ' Sue-Ellen',\n",
       "   ' Colleen',\n",
       "   ' Emily',\n",
       "   ' Megan',\n",
       "   ' Rachel',\n",
       "   ' Wendy']],\n",
       " 'age': [['Taylor',\n",
       "   ' Jamie',\n",
       "   ' Daniel',\n",
       "   ' Aubrey',\n",
       "   ' Alison',\n",
       "   ' Miranda',\n",
       "   ' Jacob',\n",
       "   ' Arthur',\n",
       "   ' Aaron',\n",
       "   ' Ethan'],\n",
       "  ['Ruth',\n",
       "   ' William',\n",
       "   ' Horace',\n",
       "   ' Mary',\n",
       "   ' Susie',\n",
       "   ' Amy',\n",
       "   ' John',\n",
       "   ' Henry',\n",
       "   ' Edward',\n",
       "   ' Elizabeth']],\n",
       " 'economic': [['rich',\n",
       "   'richer',\n",
       "   'richest',\n",
       "   'affluence',\n",
       "   'advantaged',\n",
       "   'wealthy',\n",
       "   'costly',\n",
       "   'exorbitant',\n",
       "   'expensive',\n",
       "   'exquisite',\n",
       "   'extravagant',\n",
       "   'flush',\n",
       "   'invaluable',\n",
       "   'lavish',\n",
       "   'luxuriant',\n",
       "   'luxurious',\n",
       "   'luxury',\n",
       "   'moneyed',\n",
       "   'opulent',\n",
       "   'plush',\n",
       "   'precious',\n",
       "   'priceless',\n",
       "   'privileged',\n",
       "   'prosperous',\n",
       "   'classy'],\n",
       "  ['poor',\n",
       "   'poorer',\n",
       "   'poorest',\n",
       "   'poverty',\n",
       "   'destitude',\n",
       "   'needy',\n",
       "   'impoverished',\n",
       "   'economical',\n",
       "   'inexpensive',\n",
       "   'ruined',\n",
       "   'cheap',\n",
       "   'penurious',\n",
       "   'underprivileged',\n",
       "   'penniless',\n",
       "   'valueless',\n",
       "   'penury',\n",
       "   'indigence',\n",
       "   'bankrupt',\n",
       "   'beggarly',\n",
       "   'moneyless',\n",
       "   'insolvent']]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 21\n",
      "count:   25\n",
      "count 2:   20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.78580765e-02,  6.28788750e-02, -7.58523189e-02,  8.23152863e-02,\n",
       "        -8.12157068e-03,  1.50427927e-02,  5.77271445e-02, -1.04631918e-01,\n",
       "         1.88045927e-02,  1.02404768e-01, -4.43742886e-02, -6.68432025e-02,\n",
       "         6.58769741e-02,  6.59164354e-02, -6.07808446e-02,  5.80716808e-02,\n",
       "         6.77600382e-02,  7.79177848e-02, -1.45713756e-02,  7.54993673e-02,\n",
       "        -2.82500729e-02, -3.32781611e-02,  2.70306636e-02,  5.92220398e-02,\n",
       "         8.74367768e-02,  3.71204847e-02, -3.15904487e-02,  6.44700915e-02,\n",
       "        -1.30680923e-02, -8.72942017e-02,  1.43666752e-02,  5.38476242e-02,\n",
       "         5.10431656e-02,  6.44515648e-02, -9.05238009e-03, -7.60298711e-02,\n",
       "         2.59919222e-02, -5.14201954e-02, -3.44416449e-02,  6.51286755e-03,\n",
       "         1.26016070e-01,  1.95617793e-02,  7.98833217e-02, -2.75324395e-02,\n",
       "         7.20531414e-02, -7.87375146e-02, -1.52603195e-02,  1.61302715e-01,\n",
       "        -4.23355790e-02, -2.97217172e-02,  7.51155594e-02,  3.75476783e-02,\n",
       "         3.34649931e-02, -8.88825240e-02, -9.07708946e-02,  4.85430837e-02,\n",
       "        -6.94795931e-02, -9.83704034e-02,  5.44465407e-02, -4.04029802e-02,\n",
       "         5.69485747e-03,  2.88317843e-02, -1.32374227e-01, -6.61746414e-02,\n",
       "         3.35049623e-02, -5.48956556e-02, -9.95334350e-02,  2.14537293e-02,\n",
       "         8.73309965e-03,  2.51012115e-02,  1.13498154e-01, -3.55524709e-02,\n",
       "         3.12694377e-02, -3.53779915e-03, -4.22368177e-02, -1.20191437e-02,\n",
       "        -1.17206262e-02,  8.69125634e-02,  8.14803395e-03,  6.59677040e-02,\n",
       "        -7.23219211e-02,  2.50450650e-02, -1.02553623e-01,  4.41891438e-02,\n",
       "        -6.35943436e-02, -2.46041156e-02, -5.95473311e-02,  5.76293127e-02,\n",
       "         1.05221608e-02,  5.41085679e-02, -1.51232655e-02,  7.45221282e-03,\n",
       "        -5.46314758e-02, -1.41894183e-02, -9.80787362e-02, -8.03623602e-02,\n",
       "         3.02999470e-02, -1.89636598e-02,  2.32971686e-02, -7.46949154e-02,\n",
       "        -4.95265630e-02,  3.10106654e-02,  5.05631982e-02,  4.06993982e-03,\n",
       "        -1.82364100e-02, -2.08771867e-02,  1.22384363e-01,  6.20214325e-02,\n",
       "         6.44905596e-02, -9.14495878e-02,  2.05375780e-03,  6.91448113e-02,\n",
       "         6.38431225e-03, -2.82612154e-03,  1.32172330e-01, -3.98656810e-02,\n",
       "         7.25763418e-02, -9.03082899e-02,  5.07482391e-02,  5.65650618e-02,\n",
       "        -1.83005555e-03, -7.47730622e-03,  5.06185509e-02, -1.24832135e-04,\n",
       "        -4.05294342e-02,  2.36791359e-02,  2.15531297e-02, -6.89529589e-02,\n",
       "         8.84712235e-02,  8.83088763e-03, -1.72251805e-02,  5.57215820e-02,\n",
       "         3.58093377e-03,  5.49932065e-02, -2.77479554e-02, -3.63589499e-02,\n",
       "         6.43824027e-03,  6.53115380e-02, -3.50563455e-02,  1.05197069e-01,\n",
       "        -2.69407968e-02, -1.04401453e-01, -1.38319948e-02,  5.08112580e-02,\n",
       "         1.13025182e-01, -4.08393449e-03, -1.25515231e-03,  9.95958162e-02,\n",
       "        -4.58858050e-03, -3.87784346e-02,  7.23222476e-02,  6.22375634e-02,\n",
       "         1.41935814e-02, -1.32978323e-03,  2.12269272e-03, -2.11511267e-02,\n",
       "        -7.43481915e-02, -1.50087726e-02, -7.71560316e-02, -1.18412742e-01,\n",
       "        -9.79914864e-02, -1.09106938e-02,  4.82174458e-02,  1.11895702e-02,\n",
       "         6.16252421e-03, -1.92230579e-02,  3.89286599e-02, -7.22064160e-02,\n",
       "        -1.00860388e-01,  4.64716275e-02, -1.42416525e-01, -1.75951006e-04,\n",
       "        -6.20124204e-02, -5.10081355e-02, -9.29598006e-03,  5.96481818e-03,\n",
       "        -2.96183304e-02, -1.11847669e-02, -7.35238899e-02, -1.47567944e-02,\n",
       "        -2.91535496e-02, -1.79854786e-02, -6.08463216e-02, -3.02360830e-02,\n",
       "        -5.92873845e-02, -1.18613109e-02,  3.62423798e-02, -7.91162657e-04,\n",
       "         1.33788828e-02, -6.51200798e-02, -1.53441838e-02, -2.11027557e-02,\n",
       "         7.99046960e-02, -1.63097443e-03, -1.02835542e-01,  3.91400489e-02,\n",
       "        -5.36951664e-02,  8.57230962e-03,  2.37044939e-02, -5.17327842e-02,\n",
       "         3.97452142e-02,  8.06443327e-02, -2.76282713e-02, -7.52846138e-02,\n",
       "        -1.83108460e-02, -6.88167442e-03, -2.58141147e-02, -8.24607830e-02,\n",
       "        -1.16827739e-01, -1.25773804e-02, -1.10357801e-01,  5.71829061e-02,\n",
       "         3.72778647e-02,  2.34493194e-02,  8.05900766e-02,  9.54806984e-02,\n",
       "        -3.70056424e-03,  1.07089069e-01, -1.74001051e-02,  2.73885477e-02,\n",
       "         5.10841100e-02,  5.67788511e-02, -6.27704426e-02,  1.34075500e-02,\n",
       "         5.10274207e-02,  5.51792135e-02,  1.26160333e-01, -1.73327497e-02,\n",
       "        -4.01975473e-02,  3.42574421e-02, -1.71149227e-02, -1.08339900e-02,\n",
       "        -1.77652697e-04,  1.64958621e-02,  9.99255818e-02, -4.42337795e-03,\n",
       "        -2.24798097e-02, -6.30777493e-02,  5.76734756e-02, -6.86709495e-02,\n",
       "         7.26315416e-02, -1.13347561e-01,  1.84692734e-03, -2.69155444e-02,\n",
       "         2.17291914e-03,  1.79714275e-02,  4.89767239e-02, -6.03221733e-02,\n",
       "        -2.57594833e-02, -3.66819729e-02,  7.47092661e-02,  6.41140264e-02,\n",
       "         8.69751618e-02,  7.75103912e-02, -2.57099801e-02, -5.38048935e-02,\n",
       "        -9.91444832e-02, -4.81215471e-02, -8.24607905e-02,  1.29880709e-02,\n",
       "         1.43324976e-02, -4.57444095e-03, -1.46794379e-02,  7.22164858e-02,\n",
       "         4.58843338e-02,  1.78074137e-02, -1.28451715e-01, -1.05787423e-01,\n",
       "        -4.65589995e-02,  2.52573910e-02, -7.35689801e-02,  1.00500554e-01,\n",
       "        -3.23431001e-02,  2.17872434e-02,  1.60588334e-02, -5.37191241e-02,\n",
       "         2.07450958e-02, -1.19754523e-02, -7.43469359e-02,  1.08064691e-01,\n",
       "         1.87893456e-02, -4.06042250e-02, -3.15632298e-02, -4.20496298e-02,\n",
       "        -4.58237215e-02,  1.08261474e-01, -4.35342687e-02,  1.90104308e-02,\n",
       "         8.02025309e-02, -2.68877241e-02, -4.67664779e-02, -5.58377842e-02,\n",
       "        -6.12036057e-02,  2.46424081e-03, -1.27699396e-02, -2.55185174e-02,\n",
       "        -1.71449782e-02, -3.86063799e-02,  8.90776128e-03, -5.80349436e-03]),\n",
       " array([ 6.92844776e-02,  3.30474433e-02, -4.11888286e-02,  1.02629133e-01,\n",
       "        -1.95529977e-02,  1.40685245e-01,  3.40722986e-02,  1.20098719e-02,\n",
       "         4.87002561e-02,  4.22315199e-02,  1.04933377e-02, -2.39254570e-02,\n",
       "         4.26521912e-02,  1.26941540e-01, -7.35011637e-02,  8.18514519e-02,\n",
       "         6.96107429e-02,  1.09036865e-01,  2.18398161e-03,  5.27235960e-02,\n",
       "         6.47842898e-02, -2.72300900e-02,  9.27283943e-02, -1.09233901e-02,\n",
       "         1.15102955e-01, -2.76846128e-02, -1.05924528e-01,  1.25350837e-02,\n",
       "         1.79938390e-02, -9.21637901e-02, -7.53704446e-02, -4.25248935e-02,\n",
       "         4.03498836e-02,  4.20151472e-02, -2.51651632e-02,  2.74070047e-02,\n",
       "        -2.33280339e-03, -7.80668515e-02, -3.87846176e-02,  5.44360901e-02,\n",
       "         5.40468480e-02,  3.84156173e-02,  1.13313246e-01, -6.52397052e-02,\n",
       "         8.49853041e-02, -5.44654774e-02, -5.71229641e-02,  9.43683436e-02,\n",
       "        -8.19889247e-02,  1.35779250e-02,  3.51560884e-02, -2.51658040e-02,\n",
       "        -2.14945770e-02, -7.57819554e-02, -7.74729570e-02, -7.12387822e-02,\n",
       "        -1.47024245e-01, -7.91681139e-02, -2.92483315e-02, -1.90309747e-02,\n",
       "         6.41292344e-02,  3.69407405e-02, -9.84747994e-02, -3.68859914e-02,\n",
       "         4.40721993e-02, -1.32288257e-01, -5.45420770e-02,  3.79026536e-02,\n",
       "        -3.16636837e-02, -5.61025195e-02,  3.71159400e-02, -5.01569855e-02,\n",
       "        -1.25311443e-02,  3.85931447e-02, -2.90139612e-02, -4.50686754e-02,\n",
       "        -2.57895646e-02,  8.72867624e-02,  2.30222368e-02,  2.70002183e-02,\n",
       "        -2.18397682e-04,  3.44076390e-02, -1.25236286e-01,  6.21925533e-02,\n",
       "        -6.24999191e-02,  6.47589331e-02, -9.42277688e-03,  5.25221774e-02,\n",
       "         3.97164561e-02, -3.26687853e-02, -2.24300245e-02, -1.74662114e-02,\n",
       "        -5.51577107e-02, -1.02705286e-01, -5.40280740e-02, -3.01491631e-02,\n",
       "         8.82860470e-02, -6.83039101e-03,  2.18773419e-02, -3.92031404e-02,\n",
       "         6.12527676e-03,  6.67764558e-02, -4.00022707e-02,  2.45593048e-02,\n",
       "        -7.59614060e-02, -4.64732123e-02,  2.90609111e-02, -4.53801559e-03,\n",
       "         6.08889306e-02, -6.63400583e-02,  5.85961786e-03,  2.91030579e-02,\n",
       "        -3.01143678e-02, -9.42694932e-03,  7.55989113e-02,  2.99648880e-02,\n",
       "         7.59320809e-02, -1.03257903e-01,  3.65574755e-02,  9.52626560e-02,\n",
       "        -7.24015172e-02,  2.42517006e-02, -7.80181245e-02, -8.63660729e-02,\n",
       "        -7.37107486e-02,  3.49284866e-02, -2.79497780e-02, -6.00061680e-02,\n",
       "         5.76948340e-03, -8.98298781e-02, -1.52776367e-02,  3.99697273e-02,\n",
       "        -4.70210598e-02,  4.77163552e-02, -5.93637509e-02,  3.81464345e-03,\n",
       "        -4.56785783e-02, -7.28931322e-03, -2.24169395e-02,  6.25657920e-02,\n",
       "         2.03936404e-02, -1.01877784e-01,  5.12224846e-02,  1.42240518e-01,\n",
       "         4.45147195e-02, -5.26919025e-04, -8.55471129e-02,  2.72574564e-02,\n",
       "         8.36724009e-03, -5.15951185e-03,  9.11152472e-02, -3.86271922e-02,\n",
       "        -4.45855503e-03,  4.40474017e-02, -5.83271562e-03,  1.24610818e-02,\n",
       "        -8.82438119e-02,  7.42222664e-03, -3.43867611e-02, -1.20254336e-01,\n",
       "        -7.20489778e-02,  3.19937612e-02, -6.01605254e-03,  2.88640247e-02,\n",
       "         5.06644297e-03, -3.80026236e-02,  5.17001168e-02, -5.23718327e-02,\n",
       "        -3.58766430e-02, -5.14987278e-02, -9.86174774e-02,  3.26463775e-03,\n",
       "        -7.17501628e-02, -5.70468733e-02, -1.17241803e-04,  1.04614611e-02,\n",
       "         4.81225139e-02, -9.22248811e-02,  1.26144811e-03,  3.45980151e-02,\n",
       "        -7.62278201e-02, -1.13128736e-01, -1.56181495e-02,  4.89305303e-02,\n",
       "        -6.25736770e-02, -4.19439525e-03, -3.06309721e-02,  5.57823522e-02,\n",
       "         3.67181237e-02,  4.50321654e-02, -4.26962061e-02,  2.29872056e-03,\n",
       "         4.52673351e-02, -6.02578972e-03, -5.35553811e-02,  2.26028041e-02,\n",
       "        -1.83036419e-02, -2.09588138e-02,  1.16795608e-02, -1.30807811e-02,\n",
       "        -2.51468500e-02,  5.39226174e-02,  1.90041663e-03, -1.21950097e-01,\n",
       "        -1.93547328e-02, -3.07088058e-02, -2.17036567e-02, -1.38886361e-02,\n",
       "        -1.03434626e-01, -6.79415360e-02, -3.00740438e-02,  4.38284301e-03,\n",
       "         7.54317266e-02,  3.53476791e-02,  3.89278952e-02,  6.42415666e-02,\n",
       "         1.33194572e-02,  7.70887926e-02, -6.41205352e-02,  1.76563485e-02,\n",
       "         3.14352221e-02,  4.52430817e-02, -1.37094648e-02,  8.49623573e-02,\n",
       "         5.75005063e-02,  1.58685932e-02,  7.87800434e-02, -3.23880957e-02,\n",
       "        -4.08066396e-02,  3.63717358e-02,  6.83433144e-02,  3.14905673e-02,\n",
       "         8.50551114e-02, -1.44593008e-02,  3.00769332e-02, -2.87189531e-02,\n",
       "         6.71523424e-02, -9.14324404e-02,  5.25824958e-02, -3.10376380e-02,\n",
       "         7.22922789e-02, -1.04027477e-01, -7.16985421e-03, -3.94697562e-02,\n",
       "        -2.82131944e-02,  5.42873604e-02,  5.75356901e-02, -7.76577711e-02,\n",
       "        -3.58336751e-02, -6.10160356e-02,  6.37826414e-02, -8.45461249e-02,\n",
       "         5.96649321e-02,  1.05770495e-01, -5.02990236e-03, -1.11175369e-01,\n",
       "         1.44148634e-02,  5.97635566e-04,  7.34106934e-03,  1.45051504e-02,\n",
       "        -2.94125478e-02, -1.63685070e-02,  5.23461683e-02,  5.25364828e-02,\n",
       "        -2.36520262e-02,  4.10885359e-02, -1.13970961e-01, -5.40613222e-02,\n",
       "        -2.57805429e-02, -6.64257748e-02, -6.06680685e-02,  1.12003629e-01,\n",
       "         5.10900655e-03, -8.53487767e-03, -2.58449258e-02, -2.92979259e-02,\n",
       "        -2.46403485e-02, -4.02834935e-02, -7.37064622e-02,  5.75114052e-02,\n",
       "         2.69153183e-02, -2.70912094e-02,  6.17095897e-02,  2.67145558e-02,\n",
       "        -7.40909477e-02,  8.53881162e-02, -3.00274902e-02,  9.50759022e-02,\n",
       "         3.86317051e-02, -3.47327787e-02, -6.70143939e-02,  1.27704482e-02,\n",
       "        -1.62123892e-01, -6.96116119e-03, -3.03448951e-02,  8.21163125e-02,\n",
       "        -7.56080331e-02, -4.91835407e-03,  6.09298395e-02,  3.08229269e-02]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify how many words for each bias type are actually being used to compute average vector\n",
    "t = \"economic\"\n",
    "print(len(bias_words[t][0]), len(bias_words[t][1])) \n",
    "bias_w = bias_words[t]\n",
    "groupBiasDirection(bias_w[0], bias_w[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:   20\n",
      "count 2:   19\n",
      "count:   15\n",
      "count 2:   18\n",
      "count:   46\n",
      "count 2:   48\n",
      "count:   10\n",
      "count 2:   10\n",
      "count:   25\n",
      "count 2:   20\n"
     ]
    }
   ],
   "source": [
    "all_words = list(model.vocab.keys()) #[:50000]\n",
    "#all_words = df[\"word\"].tolist()\n",
    "df = pd.DataFrame({\"word\":all_words})\n",
    "for bias_type in bias_words:\n",
    "    bias_w = bias_words[bias_type]\n",
    "    df[bias_type] = None\n",
    "    g1, g2 = groupBiasDirection(bias_w[0], bias_w[1])\n",
    "    for index, row in df.iterrows():\n",
    "        w = row[\"word\"]\n",
    "        # assuming group bias \"Quantification algo\"\n",
    "        df.at[index, bias_type] = round(cosine(g1,model[w])-cosine(g2,model[w]),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender:  -0.2914 0.3362\n",
      "Race:  -0.3131 0.3645\n",
      "Religion:  -0.3848 0.4055\n",
      "Age:  -0.2712 0.3126\n",
      "Economic:  -0.4167 0.4011\n"
     ]
    }
   ],
   "source": [
    "gen_max, gen_min = df[\"gender\"].max(), df[\"gender\"].min()\n",
    "#sen_max, sen_min = df[\"sentiment\"].max(), df[\"sentiment\"].min()\n",
    "race_max, race_min = df[\"race\"].max(), df[\"race\"].min()\n",
    "relg_max, relg_min = df[\"religion\"].max(), df[\"religion\"].min()\n",
    "age_max, age_min = df[\"age\"].max(), df[\"age\"].min()\n",
    "eco_max, eco_min = df[\"economic\"].max(), df[\"economic\"].min()\n",
    "\n",
    "print(\"Gender: \",gen_min,gen_max)\n",
    "#print(\"Sentiment: \",sen_min, sen_max)\n",
    "print(\"Race: \",race_min, race_max)\n",
    "print(\"Religion: \",relg_min, relg_max)\n",
    "print(\"Age: \",age_min, age_max)\n",
    "print(\"Economic: \",eco_min, eco_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while calculating for negative values we want the range to be [-1, 0] instead of [0,1]\n",
    "# so, we have used 'negative' parameter to flip the sign if negative values are fed \n",
    "def percentile_rank(values, col, negative=False):\n",
    "    N = len(values)\n",
    "    last_ind = -1\n",
    "    for i,items in enumerate(values.iteritems()): \n",
    "        index, val = items[0], items[1]\n",
    "        if last_ind!=-1 and val==df.at[last_ind, col]: \n",
    "            df.at[index, col] = df.at[last_ind, col] \n",
    "            #percentile.append(percentile[i-1])\n",
    "        else:\n",
    "            p = (N-i)/N\n",
    "            #print(i,p)\n",
    "            df.at[index, col] = p \n",
    "            #percentile.append(p)\n",
    "        if negative:\n",
    "            df.at[index, col] = df.at[index, col]*-1\n",
    "        last_ind = index\n",
    "\n",
    "for col in df.columns:\n",
    "    if col==\"word\":\n",
    "        continue\n",
    "    values = df.loc[df[col]>0][col].sort_values(ascending=False, inplace=False)\n",
    "    percentile_rank(values, col)\n",
    "    \n",
    "    values = df.loc[df[col]<0][col].sort_values(ascending=True, inplace=False)\n",
    "    percentile_rank(values, col, negative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.4\n",
       "1    1.0\n",
       "2    0.2\n",
       "3   -0.8\n",
       "4    0.6\n",
       "5   -1.0\n",
       "6    0.4\n",
       "7    0.6\n",
       "8    0.8\n",
       "9   -0.6\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more modular percentile_rank function\n",
    "def percentile_rank(values, negative=False):\n",
    "    out = values.copy()\n",
    "    N = len(values)\n",
    "    last_ind = -1\n",
    "    for i,items in enumerate(values.iteritems()):\n",
    "        index, val = items[0], items[1]\n",
    "        if last_ind!=-1 and val==values.get(last_ind): \n",
    "            out.at[index] = out.get(last_ind)\n",
    "            #print(\"last_ind: \",last_ind,\"  index: \",index, \" p: \",out.get(last_ind))\n",
    "        else:\n",
    "            p = (N-i)/N\n",
    "            out.at[index] = p\n",
    "            #print(\"index: \",index, \" p: \",p)\n",
    "        if negative:\n",
    "            out.at[index] = out.get(index)*-1\n",
    "        last_ind = index\n",
    "    return out\n",
    "\n",
    "arr = pd.Series([-1,7,1,-4,2,-7,-1,2,5,-2], dtype='float')\n",
    "values = arr[arr>0].sort_values(ascending=False, inplace=False)\n",
    "res1 = percentile_rank(values, negative=False)\n",
    "\n",
    "values = arr[arr<=0].sort_values(ascending=True, inplace=False)\n",
    "res2 = percentile_rank(values, negative=True)\n",
    "res = pd.concat([res1,res2])\n",
    "res = res.reindex(arr.index)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.4, 1.0, 0.2, -0.8, 0.6, -1.0, 0.4, 0.6, 0.8, -0.6]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender:  -1.0 1.0\n",
      "Race:  -1.0 1.0\n",
      "Religion:  -1.0 1.0\n",
      "Age:  -1.0 1.0\n",
      "Economic:  -1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "gen_max, gen_min = df[\"gender\"].max(), df[\"gender\"].min()\n",
    "#sen_max, sen_min = df[\"sentiment\"].max(), df[\"sentiment\"].min()\n",
    "race_max, race_min = df[\"race\"].max(), df[\"race\"].min()\n",
    "relg_max, relg_min = df[\"religion\"].max(), df[\"religion\"].min()\n",
    "age_max, age_min = df[\"age\"].max(), df[\"age\"].min()\n",
    "eco_max, eco_min = df[\"economic\"].max(), df[\"economic\"].min()\n",
    "\n",
    "print(\"Gender: \",gen_min,gen_max)\n",
    "#print(\"Sentiment: \",sen_min, sen_max)\n",
    "print(\"Race: \",race_min, race_max)\n",
    "print(\"Religion: \",relg_min, relg_max)\n",
    "print(\"Age: \",age_min, age_max)\n",
    "print(\"Economic: \",eco_min, eco_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of bias scores\n",
    "for index, row in df.iterrows():    \n",
    "    if row[\"gender\"]>0:\n",
    "        df.at[index, \"gender\"] = row[\"gender\"]/gen_max\n",
    "    else:\n",
    "        df.at[index, \"gender\"] = -1*row[\"gender\"]/gen_min\n",
    "        \n",
    "    if row[\"race\"]>0:\n",
    "        df.at[index, \"race\"] = row[\"race\"]/race_max\n",
    "    else:\n",
    "        df.at[index, \"race\"] = -1*row[\"race\"]/race_min\n",
    "    \n",
    "    #if row[\"sentiment\"]>0:\n",
    "    #    df.at[index, \"sentiment\"] = row[\"sentiment\"]/sen_max\n",
    "    #else:\n",
    "    #    df.at[index, \"sentiment\"] = -1*row[\"sentiment\"]/sen_min\n",
    "        \n",
    "    if row[\"religion\"]>0:\n",
    "        df.at[index, \"religion\"] = row[\"religion\"]/relg_max\n",
    "    else:\n",
    "        df.at[index, \"religion\"] = -1*row[\"religion\"]/relg_min\n",
    "    \n",
    "    if row[\"age\"]>0:\n",
    "        df.at[index, \"age\"] = row[\"age\"]/age_max\n",
    "    else:\n",
    "        df.at[index, \"age\"] = -1*row[\"age\"]/age_min  \n",
    "    \n",
    "    if row[\"economic\"]>0:\n",
    "        df.at[index, \"economic\"] = row[\"economic\"]/eco_max\n",
    "    else:\n",
    "        df.at[index, \"economic\"] = -1*row[\"economic\"]/eco_min  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender:  -1.0 1.0\n",
      "Race:  -1.0 1.0\n",
      "Religion:  -1.0 1.0\n",
      "Age:  -1.0 1.0\n",
      "Economic:  -1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "gen_max, gen_min = df[\"gender\"].max(), df[\"gender\"].min()\n",
    "#sen_max, sen_min = df[\"sentiment\"].max(), df[\"sentiment\"].min()\n",
    "race_max, race_min = df[\"race\"].max(), df[\"race\"].min()\n",
    "relg_max, relg_min = df[\"religion\"].max(), df[\"religion\"].min()\n",
    "age_max, age_min = df[\"age\"].max(), df[\"age\"].min()\n",
    "eco_max, eco_min = df[\"economic\"].max(), df[\"economic\"].min()\n",
    "\n",
    "print(\"Gender: \",gen_min,gen_max)\n",
    "#print(\"Sentiment: \",sen_min, sen_max)\n",
    "print(\"Race: \",race_min, race_max)\n",
    "print(\"Religion: \",relg_min, relg_max)\n",
    "print(\"Age: \",age_min, age_max)\n",
    "print(\"Economic: \",eco_min, eco_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gender</th>\n",
       "      <th>religion</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>economic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>-0.0751544</td>\n",
       "      <td>0.0054254</td>\n",
       "      <td>-0.0341744</td>\n",
       "      <td>0.0271913</td>\n",
       "      <td>-0.0357571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>-0.0840769</td>\n",
       "      <td>-0.0709459</td>\n",
       "      <td>0.105624</td>\n",
       "      <td>-0.131637</td>\n",
       "      <td>0.0703067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "      <td>-0.0549073</td>\n",
       "      <td>-0.153586</td>\n",
       "      <td>0.084225</td>\n",
       "      <td>-0.0280236</td>\n",
       "      <td>0.061082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>-0.0655456</td>\n",
       "      <td>-0.152807</td>\n",
       "      <td>0.0491084</td>\n",
       "      <td>0.00959693</td>\n",
       "      <td>0.0710546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>-0.0514756</td>\n",
       "      <td>-0.00753638</td>\n",
       "      <td>0.0899863</td>\n",
       "      <td>-0.0623156</td>\n",
       "      <td>-0.0266379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word     gender    religion       race         age   economic\n",
       "0    in -0.0751544   0.0054254 -0.0341744   0.0271913 -0.0357571\n",
       "1   for -0.0840769  -0.0709459   0.105624   -0.131637  0.0703067\n",
       "2  that -0.0549073   -0.153586   0.084225  -0.0280236   0.061082\n",
       "3    is -0.0655456   -0.152807  0.0491084  0.00959693  0.0710546\n",
       "4    on -0.0514756 -0.00753638  0.0899863  -0.0623156 -0.0266379"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gender</th>\n",
       "      <th>religion</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>economic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50175</td>\n",
       "      <td>50175.000000</td>\n",
       "      <td>50175.00000</td>\n",
       "      <td>50175.000000</td>\n",
       "      <td>50175.000000</td>\n",
       "      <td>50175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>50175</td>\n",
       "      <td>3352.000000</td>\n",
       "      <td>3447.00000</td>\n",
       "      <td>2874.000000</td>\n",
       "      <td>2420.000000</td>\n",
       "      <td>3855.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>curatorial</td>\n",
       "      <td>-0.017159</td>\n",
       "      <td>0.04143</td>\n",
       "      <td>0.019479</td>\n",
       "      <td>-0.031711</td>\n",
       "      <td>0.073049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word        gender     religion          race           age  \\\n",
       "count        50175  50175.000000  50175.00000  50175.000000  50175.000000   \n",
       "unique       50175   3352.000000   3447.00000   2874.000000   2420.000000   \n",
       "top     curatorial     -0.017159      0.04143      0.019479     -0.031711   \n",
       "freq             1     60.000000     61.00000     72.000000     78.000000   \n",
       "\n",
       "            economic  \n",
       "count   50175.000000  \n",
       "unique   3855.000000  \n",
       "top         0.073049  \n",
       "freq       52.000000  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50175, 6)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default option: min-max Normalization, _percentile option: percentile feature scaling\n",
    "\n",
    "df.to_csv(\"../data/word2vec_50k.csv\", encoding='utf-8', index=False)\n",
    "#df.to_csv(\"../data/word2vec_50k_percentile.csv\", encoding='utf-8', index=False)\n",
    "#df.to_csv(\"../data/glove_50k.csv\", encoding='utf-8', index=False)\n",
    "#df.to_csv(\"../data/glove_50k_percentile.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8128      0.344\n",
       "62       0.3336\n",
       "42430    0.3316\n",
       "57        0.312\n",
       "16295    0.3069\n",
       "          ...  \n",
       "35457    0.0001\n",
       "34752    0.0001\n",
       "32733    0.0001\n",
       "34231    0.0001\n",
       "25589    0.0001\n",
       "Name: gender, Length: 20221, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#v = [0.90, 0.87, 0.87, 0.76, 0.60, 0.32, 0.32, 0.32, 0.1, 0.05]\n",
    "values = df.loc[df[\"gender\"]>0][\"gender\"].sort_values(ascending=False, inplace=False)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100.0\n",
      "1 90.0\n",
      "3 70.0\n",
      "4 60.0\n",
      "5 50.0\n",
      "8 20.0\n",
      "9 10.0\n"
     ]
    }
   ],
   "source": [
    "percentile = []\n",
    "N = len(values)\n",
    "for i, val in enumerate(values):\n",
    "    if val==values[i-1]:\n",
    "        percentile.append(percentile[i-1])\n",
    "        continue\n",
    "    p = (N-i)/N*100\n",
    "    print(i,p)\n",
    "    percentile.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0, 90.0, 90.0, 70.0, 60.0, 50.0, 50.0, 50.0, 20.0, 10.0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8128      0.344\n",
       "62       0.3336\n",
       "42430    0.3316\n",
       "57        0.312\n",
       "16295    0.3069\n",
       "          ...  \n",
       "35457    0.0001\n",
       "34752    0.0001\n",
       "32733    0.0001\n",
       "34231    0.0001\n",
       "25589    0.0001\n",
       "Name: gender, Length: 20221, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"gender\"]>0][\"gender\"].sort_values(ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gender</th>\n",
       "      <th>religion</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>-0.0391</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>0.0433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>-0.0491</td>\n",
       "      <td>-0.0273</td>\n",
       "      <td>-0.0058</td>\n",
       "      <td>-0.0341</td>\n",
       "      <td>-0.0399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "      <td>-0.0621</td>\n",
       "      <td>-0.0591</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>-0.0792</td>\n",
       "      <td>-0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>-0.0432</td>\n",
       "      <td>-0.0588</td>\n",
       "      <td>-0.0449</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>-0.0266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>-0.0459</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>-0.0537</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50036</th>\n",
       "      <td>salaam</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>-0.1961</td>\n",
       "      <td>-0.1378</td>\n",
       "      <td>-0.1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50037</th>\n",
       "      <td>sunni</td>\n",
       "      <td>-0.0334</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>-0.1787</td>\n",
       "      <td>-0.1393</td>\n",
       "      <td>-0.0103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50038</th>\n",
       "      <td>koran</td>\n",
       "      <td>-0.0474</td>\n",
       "      <td>0.1698</td>\n",
       "      <td>-0.0362</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50039</th>\n",
       "      <td>shiite</td>\n",
       "      <td>-0.0162</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>-0.1113</td>\n",
       "      <td>-0.1006</td>\n",
       "      <td>0.1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50040</th>\n",
       "      <td>muhammad</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>-0.0655</td>\n",
       "      <td>-0.0794</td>\n",
       "      <td>0.0423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50041 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  gender religion    race     age sentiment\n",
       "0            in -0.0391   0.0022  0.0182 -0.0031    0.0433\n",
       "1           for -0.0491  -0.0273 -0.0058 -0.0341   -0.0399\n",
       "2          that -0.0621  -0.0591  0.0078 -0.0792   -0.0582\n",
       "3            is -0.0432  -0.0588 -0.0449  0.0088   -0.0266\n",
       "4            on -0.0459  -0.0029  0.0526 -0.0537    0.0032\n",
       "...         ...     ...      ...     ...     ...       ...\n",
       "50036    salaam  -0.005   0.2614 -0.1961 -0.1378   -0.1366\n",
       "50037     sunni -0.0334   0.2043 -0.1787 -0.1393   -0.0103\n",
       "50038     koran -0.0474   0.1698 -0.0362  -0.106    0.1036\n",
       "50039    shiite -0.0162   0.2177 -0.1113 -0.1006    0.1197\n",
       "50040  muhammad -0.0063   0.2415 -0.0655 -0.0794    0.0423\n",
       "\n",
       "[50041 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if col==\"word\":\n",
    "        continue\n",
    "    values = df.loc[df[col]>0][col].sort_values(ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of bias scores\n",
    "'''\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"gender\"]>0:\n",
    "        df.at[index, \"gender\"] = row[\"gender\"]/gen_max\n",
    "    else:\n",
    "        df.at[index, \"gender\"] = -1*row[\"gender\"]/gen_min\n",
    "        \n",
    "    if row[\"race\"]>0:\n",
    "        df.at[index, \"race\"] = row[\"race\"]/race_max\n",
    "    else:\n",
    "        df.at[index, \"race\"] = -1*row[\"race\"]/race_min\n",
    "    \n",
    "    if row[\"sentiment\"]>0:\n",
    "        df.at[index, \"sentiment\"] = row[\"sentiment\"]/sen_max\n",
    "    else:\n",
    "        df.at[index, \"sentiment\"] = -1*row[\"sentiment\"]/sen_min\n",
    "        \n",
    "    if row[\"religion\"]>0:\n",
    "        df.at[index, \"religion\"] = row[\"religion\"]/relg_max\n",
    "    else:\n",
    "        df.at[index, \"religion\"] = -1*row[\"religion\"]/relg_min\n",
    "    \n",
    "    if row[\"age\"]>0:\n",
    "        df.at[index, \"age\"] = row[\"age\"]/age_max\n",
    "    else:\n",
    "        df.at[index, \"age\"] = -1*row[\"age\"]/age_min  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

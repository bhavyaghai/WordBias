{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import glob\n",
    "import gensim\n",
    "from gensim import utils\n",
    "from numpy import zeros, dtype, float32 as REAL, ascontiguousarray, fromstring\n",
    "import re\n",
    "import codecs\n",
    "import os\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>write dictionary to bin format</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://stackoverflow.com/questions/45981305/convert-python-dictionary-to-word2vec-object\n",
    "def my_save_word2vec_format(fname, vocab, vectors, binary=True, total_vec=2):\n",
    "    \"\"\"Store the input-hidden weight matrix in the same format used by the original\n",
    "    C word2vec-tool, for compatibility.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        The file path used to save the vectors in.\n",
    "    vocab : dict\n",
    "        The vocabulary of words.\n",
    "    vectors : numpy.array\n",
    "        The vectors to be stored.\n",
    "    binary : bool, optional\n",
    "        If True, the data wil be saved in binary word2vec format, else it will be saved in plain text.\n",
    "    total_vec : int, optional\n",
    "        Explicitly specify total number of vectors\n",
    "        (in case word vectors are appended with document vectors afterwards).\n",
    "\n",
    "    \"\"\"\n",
    "    if not (vocab or vectors):\n",
    "        raise RuntimeError(\"no input\")\n",
    "    if total_vec is None:\n",
    "        total_vec = len(vocab)\n",
    "    vector_size = vectors.shape[1]\n",
    "    assert (len(vocab), vector_size) == vectors.shape\n",
    "    with utils.smart_open(fname, 'wb') as fout:\n",
    "        print(total_vec, vector_size)\n",
    "        fout.write(utils.to_utf8(\"%s %s\\n\" % (total_vec, vector_size)))\n",
    "        # store in sorted order: most frequent words at the top\n",
    "        for word, row in vocab.items():\n",
    "            if binary:\n",
    "                row = row.astype(REAL)\n",
    "                fout.write(utils.to_utf8(word) + b\" \" + row.tostring())\n",
    "            else:\n",
    "                fout.write(utils.to_utf8(\"%s %s\\n\" % (word, ' '.join(repr(val) for val in row))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load word embedding model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/word_embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\smart_open\\smart_open_lib.py:251: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading word2vec embedding\n",
    "# Source link: https://code.google.com/archive/p/word2vec/\n",
    "model =  word2vec.KeyedVectors.load_word2vec_format(path+'./GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\smart_open\\smart_open_lib.py:251: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading Glove embedding\n",
    "# source: https://nlp.stanford.edu/projects/glove/\n",
    "# reformat glove embedding link: https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# convert to gensim format and save as txt file\n",
    "glove2word2vec(glove_input_file=path+\"glove.6B.300d.txt\", word2vec_output_file=path+\"gensim_glove_vectors.txt\")\n",
    "model = KeyedVectors.load_word2vec_format(path+\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\smart_open\\smart_open_lib.py:251: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(path+\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of words\n",
    "len(list(model.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of each word\n",
    "dim = model[\"he\"].shape[0]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.vocab.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary words \n",
    "nec_words = \"\"\n",
    "bias_words_path = \"../data/wordList/groups/en/\"\n",
    "\n",
    "for f in glob.glob(bias_words_path+\"*\"):\n",
    "    if os.path.isdir(f):\n",
    "        continue\n",
    "    fi = open(f, \"r\")\n",
    "    nec_words = nec_words + ','.join(fi.readlines())\n",
    "    fi.close()\n",
    "#print(nec_words)\n",
    "\n",
    "target_words_path = \"../data/wordList/target/en/\"\n",
    "\n",
    "for f in glob.glob(target_words_path+\"*\"):\n",
    "    if os.path.isdir(f):\n",
    "        continue\n",
    "    fi = open(f, \"r\")\n",
    "    nec_words = nec_words + ','.join(fi.readlines())\n",
    "    fi.close()    \n",
    "\n",
    "#nec_words = nec_words.lower()\n",
    "tmp = re.split(r'[\\n\\t, ]+', nec_words)\n",
    "nec_words = [x for x in tmp if len(x)>0]\n",
    "\n",
    "# number of necessary words\n",
    "len(nec_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ruth',\n",
       " 'William',\n",
       " 'Horace',\n",
       " 'Mary',\n",
       " 'Susie',\n",
       " 'Amy',\n",
       " 'John',\n",
       " 'Henry',\n",
       " 'Edward',\n",
       " 'Elizabeth',\n",
       " 'Taylor',\n",
       " 'Jamie',\n",
       " 'Daniel',\n",
       " 'Aubrey',\n",
       " 'Alison',\n",
       " 'Miranda',\n",
       " 'Jacob',\n",
       " 'Arthur',\n",
       " 'Aaron',\n",
       " 'Ethan',\n",
       " 'poor',\n",
       " 'poorer',\n",
       " 'poorest',\n",
       " 'poverty',\n",
       " 'destitude',\n",
       " 'needy',\n",
       " 'impoverished',\n",
       " 'economical',\n",
       " 'inexpensive',\n",
       " 'ruined',\n",
       " 'cheap',\n",
       " 'penurious',\n",
       " 'underprivileged',\n",
       " 'penniless',\n",
       " 'valueless',\n",
       " 'penury',\n",
       " 'indigence',\n",
       " 'bankrupt',\n",
       " 'beggarly',\n",
       " 'moneyless',\n",
       " 'insolvent',\n",
       " 'rich',\n",
       " 'richer',\n",
       " 'richest',\n",
       " 'affluence',\n",
       " 'advantaged',\n",
       " 'wealthy',\n",
       " 'costly',\n",
       " 'exorbitant',\n",
       " 'expensive',\n",
       " 'exquisite',\n",
       " 'extravagant',\n",
       " 'flush',\n",
       " 'invaluable',\n",
       " 'lavish',\n",
       " 'luxuriant',\n",
       " 'luxurious',\n",
       " 'luxury',\n",
       " 'moneyed',\n",
       " 'opulent',\n",
       " 'plush',\n",
       " 'precious',\n",
       " 'priceless',\n",
       " 'privileged',\n",
       " 'prosperous',\n",
       " 'classy',\n",
       " 'she',\n",
       " 'daughter',\n",
       " 'hers',\n",
       " 'her',\n",
       " 'mother',\n",
       " 'woman',\n",
       " 'girl',\n",
       " 'herself',\n",
       " 'female',\n",
       " 'sister',\n",
       " 'daughters',\n",
       " 'mothers',\n",
       " 'women',\n",
       " 'girls',\n",
       " 'femen',\n",
       " 'sisters',\n",
       " 'aunt',\n",
       " 'aunts',\n",
       " 'niece',\n",
       " 'nieces',\n",
       " 'he',\n",
       " 'son',\n",
       " 'his',\n",
       " 'him',\n",
       " 'father',\n",
       " 'man',\n",
       " 'boy',\n",
       " 'himself',\n",
       " 'male',\n",
       " 'brother',\n",
       " 'sons',\n",
       " 'fathers',\n",
       " 'men',\n",
       " 'boys',\n",
       " 'males',\n",
       " 'brothers',\n",
       " 'uncle',\n",
       " 'uncles',\n",
       " 'nephew',\n",
       " 'nephews',\n",
       " 'black',\n",
       " 'blacks',\n",
       " 'Black',\n",
       " 'Blacks',\n",
       " 'African',\n",
       " 'african',\n",
       " 'Afro',\n",
       " 'white',\n",
       " 'whites',\n",
       " 'White',\n",
       " 'Whites',\n",
       " 'Caucasian',\n",
       " 'caucasian',\n",
       " 'European',\n",
       " 'european',\n",
       " 'Anglo',\n",
       " 'baptism',\n",
       " 'messiah',\n",
       " 'catholicism',\n",
       " 'resurrection',\n",
       " 'christianity',\n",
       " 'salvation',\n",
       " 'protestant',\n",
       " 'gospel',\n",
       " 'trinity',\n",
       " 'jesus',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'cross',\n",
       " 'catholic',\n",
       " 'church',\n",
       " 'allah',\n",
       " 'ramadan',\n",
       " 'turban',\n",
       " 'emir',\n",
       " 'salaam',\n",
       " 'sunni',\n",
       " 'koran',\n",
       " 'imam',\n",
       " 'sultan',\n",
       " 'prophet',\n",
       " 'veil',\n",
       " 'ayatollah',\n",
       " 'shiite',\n",
       " 'mosque',\n",
       " 'islam',\n",
       " 'sheik',\n",
       " 'muslim',\n",
       " 'muhammad',\n",
       " 'caress',\n",
       " 'freedom',\n",
       " 'health',\n",
       " 'love',\n",
       " 'peace',\n",
       " 'cheer',\n",
       " 'friend',\n",
       " 'heaven',\n",
       " 'loyal',\n",
       " 'pleasure',\n",
       " 'diamond',\n",
       " 'gentle',\n",
       " 'honest',\n",
       " 'lucky',\n",
       " 'rainbow',\n",
       " 'diploma',\n",
       " 'gift',\n",
       " 'honor',\n",
       " 'miracle',\n",
       " 'sunrise',\n",
       " 'family',\n",
       " 'happy',\n",
       " 'laughter',\n",
       " 'paradise',\n",
       " 'vacation',\n",
       " 'abuse',\n",
       " 'crash',\n",
       " 'filth',\n",
       " 'murder',\n",
       " 'sickness',\n",
       " 'accident',\n",
       " 'death',\n",
       " 'grief',\n",
       " 'poison',\n",
       " 'stink',\n",
       " 'assault',\n",
       " 'disaster',\n",
       " 'hatred',\n",
       " 'pollute',\n",
       " 'tragedy',\n",
       " 'divorce',\n",
       " 'jail',\n",
       " 'poverty',\n",
       " 'ugly',\n",
       " 'cancer',\n",
       " 'kill',\n",
       " 'rotten',\n",
       " 'vomit',\n",
       " 'agony',\n",
       " 'prison',\n",
       " 'terror',\n",
       " 'terrorism',\n",
       " 'violence',\n",
       " 'attack',\n",
       " 'death',\n",
       " 'military',\n",
       " 'war',\n",
       " 'radical',\n",
       " 'injuries',\n",
       " 'bomb',\n",
       " 'target',\n",
       " 'conflict',\n",
       " 'dangerous',\n",
       " 'kill',\n",
       " 'murder',\n",
       " 'strike',\n",
       " 'dead',\n",
       " 'violence',\n",
       " 'fight',\n",
       " 'death',\n",
       " 'force',\n",
       " 'stronghold',\n",
       " 'wreckage',\n",
       " 'aggression',\n",
       " 'slaughter',\n",
       " 'execute',\n",
       " 'overthrow',\n",
       " 'casualties',\n",
       " 'massacre',\n",
       " 'retaliation',\n",
       " 'proliferation',\n",
       " 'militia',\n",
       " 'hostility',\n",
       " 'debris',\n",
       " 'acid',\n",
       " 'execution',\n",
       " 'militant',\n",
       " 'rocket',\n",
       " 'guerrilla',\n",
       " 'sacrifice',\n",
       " 'enemy',\n",
       " 'soldier',\n",
       " 'terrorist',\n",
       " 'missile',\n",
       " 'hostile',\n",
       " 'revolution',\n",
       " 'resistance',\n",
       " 'shoot',\n",
       " 'adventurous',\n",
       " 'helpful',\n",
       " 'affable',\n",
       " 'humble',\n",
       " 'capable',\n",
       " 'imaginative',\n",
       " 'charming',\n",
       " 'impartial',\n",
       " 'confident',\n",
       " 'independent',\n",
       " 'conscientious',\n",
       " 'keen',\n",
       " 'cultured',\n",
       " 'meticulous',\n",
       " 'dependable',\n",
       " 'observant',\n",
       " 'discreet',\n",
       " 'optimistic',\n",
       " 'persistent',\n",
       " 'encouraging',\n",
       " 'precise',\n",
       " 'exuberant',\n",
       " 'reliable',\n",
       " 'fair',\n",
       " 'trusting',\n",
       " 'fearless',\n",
       " 'valiant',\n",
       " 'gregarious',\n",
       " 'arrogant',\n",
       " 'rude',\n",
       " 'sarcastic',\n",
       " 'cowardly',\n",
       " 'dishonest',\n",
       " 'sneaky',\n",
       " 'stingy',\n",
       " 'impulsive',\n",
       " 'sullen',\n",
       " 'lazy',\n",
       " 'surly',\n",
       " 'malicious',\n",
       " 'obnoxious',\n",
       " 'unfriendly',\n",
       " 'picky',\n",
       " 'unruly',\n",
       " 'pompous',\n",
       " 'vulgar',\n",
       " 'alluring',\n",
       " 'voluptuous',\n",
       " 'blushing',\n",
       " 'homely',\n",
       " 'plump',\n",
       " 'sensual',\n",
       " 'gorgeous',\n",
       " 'slim',\n",
       " 'bald',\n",
       " 'athletic',\n",
       " 'fashionable',\n",
       " 'stout',\n",
       " 'ugly',\n",
       " 'muscular',\n",
       " 'slender',\n",
       " 'feeble',\n",
       " 'handsome',\n",
       " 'healthy',\n",
       " 'attractive',\n",
       " 'fat',\n",
       " 'weak',\n",
       " 'thin',\n",
       " 'pretty',\n",
       " 'beautiful',\n",
       " 'strong',\n",
       " 'teacher',\n",
       " 'author',\n",
       " 'mechanic',\n",
       " 'broker',\n",
       " 'baker',\n",
       " 'surveyor',\n",
       " 'laborer',\n",
       " 'surgeon',\n",
       " 'gardener',\n",
       " 'painter',\n",
       " 'dentist',\n",
       " 'janitor',\n",
       " 'athlete',\n",
       " 'manager',\n",
       " 'conductor',\n",
       " 'carpenter',\n",
       " 'housekeeper',\n",
       " 'secretary',\n",
       " 'economist',\n",
       " 'geologist',\n",
       " 'clerk',\n",
       " 'doctor',\n",
       " 'judge',\n",
       " 'physician',\n",
       " 'lawyer',\n",
       " 'artist',\n",
       " 'instructor',\n",
       " 'dancer',\n",
       " 'photographer',\n",
       " 'inspector',\n",
       " 'musician',\n",
       " 'soldier',\n",
       " 'librarian',\n",
       " 'professor',\n",
       " 'psychologist',\n",
       " 'nurse',\n",
       " 'sailor',\n",
       " 'accountant',\n",
       " 'architect',\n",
       " 'chemist',\n",
       " 'administrator',\n",
       " 'physicist',\n",
       " 'scientist',\n",
       " 'farmer']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nec_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "destitude\n",
      "femen\n",
      "Number of words not in model:  2\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for w in nec_words:\n",
    "    if w not in model:\n",
    "        cnt = cnt + 1\n",
    "        print(w)\n",
    "print(\"Number of words not in model: \", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-634f63734488>:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  model.wv.index2entity[:10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find most frequent words \n",
    "# Ref: https://stackoverflow.com/questions/53621737/gensim-word2vec-retrieve-n-most-frequent-words\n",
    "model.wv.index2entity[:10]\n",
    "# It seems default ordering is sorted by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for w in list(model.vocab.keys()):\n",
    "    if w.isalpha() and w.islower() and len(w)<20:\n",
    "        words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words[:50000]\n",
    "for w in nec_words:\n",
    "    if w not in words and w in model:\n",
    "        words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {}\n",
    "for w in words:\n",
    "    data_dic[w] = model[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50045"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dic_to_gensim_bin_format(data_dic, file_name, path=\"../data/word_embeddings/\"):\n",
    "    vec_size = dim\n",
    "    m = gensim.models.keyedvectors.Word2VecKeyedVectors(vector_size=vec_size)\n",
    "    m.vocab = data_dic\n",
    "    m.vectors = np.array(list(data_dic.values()))\n",
    "    my_save_word2vec_format(binary=True, fname=path+file_name+'.bin', total_vec=len(data_dic), vocab=m.vocab, vectors=m.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50045 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-78eef57f9deb>:34: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  fout.write(utils.to_utf8(word) + b\" \" + row.tostring())\n"
     ]
    }
   ],
   "source": [
    "save_dic_to_gensim_bin_format(data_dic, 'word2vec_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50024 300\n"
     ]
    }
   ],
   "source": [
    "save_dic_to_gensim_bin_format(data_dic, 'glove_50k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

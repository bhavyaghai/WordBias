{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import glob\n",
    "import gensim\n",
    "from gensim import utils\n",
    "from numpy import zeros, dtype, float32 as REAL, ascontiguousarray, fromstring\n",
    "import re\n",
    "import codecs\n",
    "import os\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>write dictionary to bin format</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://stackoverflow.com/questions/45981305/convert-python-dictionary-to-word2vec-object\n",
    "def my_save_word2vec_format(fname, vocab, vectors, binary=True, total_vec=2):\n",
    "    \"\"\"Store the input-hidden weight matrix in the same format used by the original\n",
    "    C word2vec-tool, for compatibility.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        The file path used to save the vectors in.\n",
    "    vocab : dict\n",
    "        The vocabulary of words.\n",
    "    vectors : numpy.array\n",
    "        The vectors to be stored.\n",
    "    binary : bool, optional\n",
    "        If True, the data wil be saved in binary word2vec format, else it will be saved in plain text.\n",
    "    total_vec : int, optional\n",
    "        Explicitly specify total number of vectors\n",
    "        (in case word vectors are appended with document vectors afterwards).\n",
    "\n",
    "    \"\"\"\n",
    "    if not (vocab or vectors):\n",
    "        raise RuntimeError(\"no input\")\n",
    "    if total_vec is None:\n",
    "        total_vec = len(vocab)\n",
    "    vector_size = vectors.shape[1]\n",
    "    assert (len(vocab), vector_size) == vectors.shape\n",
    "    with utils.smart_open(fname, 'wb') as fout:\n",
    "        print(total_vec, vector_size)\n",
    "        fout.write(utils.to_utf8(\"%s %s\\n\" % (total_vec, vector_size)))\n",
    "        # store in sorted order: most frequent words at the top\n",
    "        for word, row in vocab.items():\n",
    "            if binary:\n",
    "                row = row.astype(REAL)\n",
    "                fout.write(utils.to_utf8(word) + b\" \" + row.tostring())\n",
    "            else:\n",
    "                fout.write(utils.to_utf8(\"%s %s\\n\" % (word, ' '.join(repr(val) for val in row))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load word embedding model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/word_embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading word2vec embedding\n",
    "# Source link: https://code.google.com/archive/p/word2vec/\n",
    "model =  word2vec.KeyedVectors.load_word2vec_format(path+'./GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\smart_open\\smart_open_lib.py:251: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading Glove embedding\n",
    "# source: https://nlp.stanford.edu/projects/glove/\n",
    "# reformat glove embedding link: https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# convert to gensim format and save as txt file\n",
    "glove2word2vec(glove_input_file=path+\"glove.6B.300d.txt\", word2vec_output_file=path+\"gensim_glove_vectors.txt\")\n",
    "model = KeyedVectors.load_word2vec_format(path+\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\smart_open\\smart_open_lib.py:251: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(path+\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of words\n",
    "len(list(model.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of each word\n",
    "dim = model[\"he\"].shape[0]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.vocab.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary words \n",
    "nec_words = \"\"\n",
    "bias_words_path = \"../data/wordList/groups/en/\"\n",
    "\n",
    "for f in glob.glob(bias_words_path+\"*\"):\n",
    "    if os.path.isdir(f):\n",
    "        continue\n",
    "    fi = open(f, \"r\")\n",
    "    nec_words = nec_words + ','.join(fi.readlines())\n",
    "    fi.close()\n",
    "#print(nec_words)\n",
    "\n",
    "target_words_path = \"../data/wordList/target/en/\"\n",
    "\n",
    "for f in glob.glob(target_words_path+\"*\"):\n",
    "    if os.path.isdir(f):\n",
    "        continue\n",
    "    fi = open(f, \"r\")\n",
    "    nec_words = nec_words + ','.join(fi.readlines())\n",
    "    fi.close()    \n",
    "\n",
    "#nec_words = nec_words.lower()\n",
    "tmp = re.split(r'[\\n\\t, ]+', nec_words)\n",
    "nec_words = [x for x in tmp if len(x)>0]\n",
    "\n",
    "# number of necessary words\n",
    "len(nec_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethel',\n",
       " 'Bernice',\n",
       " 'Gertrude',\n",
       " 'Agnes',\n",
       " 'Cecil',\n",
       " 'Wilbert',\n",
       " 'Mortimer',\n",
       " 'Edgar',\n",
       " 'Tiffany',\n",
       " 'Michelle',\n",
       " 'Cindy',\n",
       " 'Kristy',\n",
       " 'Brad',\n",
       " 'Eric',\n",
       " 'Joey',\n",
       " 'Billy',\n",
       " 'she',\n",
       " 'daughter',\n",
       " 'hers',\n",
       " 'her',\n",
       " 'mother',\n",
       " 'woman',\n",
       " 'girl',\n",
       " 'herself',\n",
       " 'female',\n",
       " 'sister',\n",
       " 'daughters',\n",
       " 'mothers',\n",
       " 'women',\n",
       " 'girls',\n",
       " 'femen',\n",
       " 'sisters',\n",
       " 'aunt',\n",
       " 'aunts',\n",
       " 'niece',\n",
       " 'nieces',\n",
       " 'he',\n",
       " 'son',\n",
       " 'his',\n",
       " 'him',\n",
       " 'father',\n",
       " 'man',\n",
       " 'boy',\n",
       " 'himself',\n",
       " 'male',\n",
       " 'brother',\n",
       " 'sons',\n",
       " 'fathers',\n",
       " 'men',\n",
       " 'boys',\n",
       " 'males',\n",
       " 'brothers',\n",
       " 'uncle',\n",
       " 'uncles',\n",
       " 'nephew',\n",
       " 'nephews',\n",
       " 'Aisha',\n",
       " 'Keisha',\n",
       " 'Tamika',\n",
       " 'Lakisha',\n",
       " 'Tanisha',\n",
       " 'Latoya',\n",
       " 'Kenya',\n",
       " 'Latonya',\n",
       " 'Ebony',\n",
       " 'Rasheed',\n",
       " 'Tremayne',\n",
       " 'Kareem',\n",
       " 'Darnell',\n",
       " 'Tyrone',\n",
       " 'Hakim',\n",
       " 'Jamal',\n",
       " 'Leroy',\n",
       " 'Jermaine',\n",
       " 'Emily',\n",
       " 'Anne',\n",
       " 'Jill',\n",
       " 'Allison',\n",
       " 'Laurie',\n",
       " 'Sarah',\n",
       " 'Meredith',\n",
       " 'Carrie',\n",
       " 'Kristen',\n",
       " 'Todd',\n",
       " 'Neil',\n",
       " 'Geoffrey',\n",
       " 'Brett',\n",
       " 'Brendan',\n",
       " 'Greg',\n",
       " 'Matthew',\n",
       " 'Jay',\n",
       " 'Brad',\n",
       " 'Harris',\n",
       " 'Nelson',\n",
       " 'Robinson',\n",
       " 'Thompson',\n",
       " 'Moore',\n",
       " 'Wright',\n",
       " 'Anderson',\n",
       " 'Clark',\n",
       " 'Jackson',\n",
       " 'Taylor',\n",
       " 'Scott',\n",
       " 'Davis',\n",
       " 'Allen',\n",
       " 'Adams',\n",
       " 'Lewis',\n",
       " 'Williams',\n",
       " 'Jones',\n",
       " 'Wilson',\n",
       " 'Martin',\n",
       " 'Johnson',\n",
       " 'baptism',\n",
       " 'messiah',\n",
       " 'catholicism',\n",
       " 'resurrection',\n",
       " 'christianity',\n",
       " 'salvation',\n",
       " 'protestant',\n",
       " 'gospel',\n",
       " 'trinity',\n",
       " 'jesus',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'cross',\n",
       " 'catholic',\n",
       " 'church',\n",
       " 'allah',\n",
       " 'ramadan',\n",
       " 'turban',\n",
       " 'emir',\n",
       " 'salaam',\n",
       " 'sunni',\n",
       " 'koran',\n",
       " 'imam',\n",
       " 'sultan',\n",
       " 'prophet',\n",
       " 'veil',\n",
       " 'ayatollah',\n",
       " 'shiite',\n",
       " 'mosque',\n",
       " 'islam',\n",
       " 'sheik',\n",
       " 'muslim',\n",
       " 'muhammad',\n",
       " 'caress',\n",
       " 'freedom',\n",
       " 'health',\n",
       " 'love',\n",
       " 'peace',\n",
       " 'cheer',\n",
       " 'friend',\n",
       " 'heaven',\n",
       " 'loyal',\n",
       " 'pleasure',\n",
       " 'diamond',\n",
       " 'gentle',\n",
       " 'honest',\n",
       " 'lucky',\n",
       " 'rainbow',\n",
       " 'diploma',\n",
       " 'gift',\n",
       " 'honor',\n",
       " 'miracle',\n",
       " 'sunrise',\n",
       " 'family',\n",
       " 'happy',\n",
       " 'laughter',\n",
       " 'paradise',\n",
       " 'vacation',\n",
       " 'abuse',\n",
       " 'crash',\n",
       " 'filth',\n",
       " 'murder',\n",
       " 'sickness',\n",
       " 'accident',\n",
       " 'death',\n",
       " 'grief',\n",
       " 'poison',\n",
       " 'stink',\n",
       " 'assault',\n",
       " 'disaster',\n",
       " 'hatred',\n",
       " 'pollute',\n",
       " 'tragedy',\n",
       " 'divorce',\n",
       " 'jail',\n",
       " 'poverty',\n",
       " 'ugly',\n",
       " 'cancer',\n",
       " 'kill',\n",
       " 'rotten',\n",
       " 'vomit',\n",
       " 'agony',\n",
       " 'prison',\n",
       " 'terror',\n",
       " 'terrorism',\n",
       " 'violence',\n",
       " 'attack',\n",
       " 'death',\n",
       " 'military',\n",
       " 'war',\n",
       " 'radical',\n",
       " 'injuries',\n",
       " 'bomb',\n",
       " 'target',\n",
       " 'conflict',\n",
       " 'dangerous',\n",
       " 'kill',\n",
       " 'murder',\n",
       " 'strike',\n",
       " 'dead',\n",
       " 'violence',\n",
       " 'fight',\n",
       " 'death',\n",
       " 'force',\n",
       " 'stronghold',\n",
       " 'wreckage',\n",
       " 'aggression',\n",
       " 'slaughter',\n",
       " 'execute',\n",
       " 'overthrow',\n",
       " 'casualties',\n",
       " 'massacre',\n",
       " 'retaliation',\n",
       " 'proliferation',\n",
       " 'militia',\n",
       " 'hostility',\n",
       " 'debris',\n",
       " 'acid',\n",
       " 'execution',\n",
       " 'militant',\n",
       " 'rocket',\n",
       " 'guerrilla',\n",
       " 'sacrifice',\n",
       " 'enemy',\n",
       " 'soldier',\n",
       " 'terrorist',\n",
       " 'missile',\n",
       " 'hostile',\n",
       " 'revolution',\n",
       " 'resistance',\n",
       " 'shoot',\n",
       " 'Adventurous',\n",
       " 'Helpful',\n",
       " 'Affable',\n",
       " 'Humble',\n",
       " 'Capable',\n",
       " 'Imaginative',\n",
       " 'Charming',\n",
       " 'Impartial',\n",
       " 'Confident',\n",
       " 'Independent',\n",
       " 'Conscientious',\n",
       " 'Keen',\n",
       " 'Cultured',\n",
       " 'Meticulous',\n",
       " 'Dependable',\n",
       " 'Observant',\n",
       " 'Discreet',\n",
       " 'Optimistic',\n",
       " 'Persistent',\n",
       " 'Encouraging',\n",
       " 'Precise',\n",
       " 'Exuberant',\n",
       " 'Reliable',\n",
       " 'Fair',\n",
       " 'Trusting',\n",
       " 'Fearless',\n",
       " 'Valiant',\n",
       " 'Gregarious',\n",
       " 'Arrogant',\n",
       " 'Rude',\n",
       " 'Sarcastic',\n",
       " 'Cowardly',\n",
       " 'Dishonest',\n",
       " 'Sneaky',\n",
       " 'Stingy',\n",
       " 'Impulsive',\n",
       " 'Sullen',\n",
       " 'Lazy',\n",
       " 'Surly',\n",
       " 'Malicious',\n",
       " 'Obnoxious',\n",
       " 'Unfriendly',\n",
       " 'Picky',\n",
       " 'Unruly',\n",
       " 'Pompous',\n",
       " 'Vulgar',\n",
       " 'alluring',\n",
       " 'voluptuous',\n",
       " 'blushing',\n",
       " 'homely',\n",
       " 'plump',\n",
       " 'sensual',\n",
       " 'gorgeous',\n",
       " 'slim',\n",
       " 'bald',\n",
       " 'athletic',\n",
       " 'fashionable',\n",
       " 'stout',\n",
       " 'ugly',\n",
       " 'muscular',\n",
       " 'slender',\n",
       " 'feeble',\n",
       " 'handsome',\n",
       " 'healthy',\n",
       " 'attractive',\n",
       " 'fat',\n",
       " 'weak',\n",
       " 'thin',\n",
       " 'pretty',\n",
       " 'beautiful',\n",
       " 'strong',\n",
       " 'teacher',\n",
       " 'author',\n",
       " 'mechanic',\n",
       " 'broker',\n",
       " 'baker',\n",
       " 'surveyor',\n",
       " 'laborer',\n",
       " 'surgeon',\n",
       " 'gardener',\n",
       " 'painter',\n",
       " 'dentist',\n",
       " 'janitor',\n",
       " 'athlete',\n",
       " 'manager',\n",
       " 'conductor',\n",
       " 'carpenter',\n",
       " 'housekeeper',\n",
       " 'secretary',\n",
       " 'economist',\n",
       " 'geologist',\n",
       " 'clerk',\n",
       " 'doctor',\n",
       " 'judge',\n",
       " 'physician',\n",
       " 'lawyer',\n",
       " 'artist',\n",
       " 'instructor',\n",
       " 'dancer',\n",
       " 'photographer',\n",
       " 'inspector',\n",
       " 'musician',\n",
       " 'soldier',\n",
       " 'librarian',\n",
       " 'professor',\n",
       " 'psychologist',\n",
       " 'nurse',\n",
       " 'sailor',\n",
       " 'accountant',\n",
       " 'architect',\n",
       " 'chemist',\n",
       " 'administrator',\n",
       " 'physicist',\n",
       " 'scientist',\n",
       " 'farmer']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nec_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "femen\n",
      "Number of words not in model:  1\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for w in nec_words:\n",
    "    if w not in model:\n",
    "        cnt = cnt + 1\n",
    "        print(w)\n",
    "print(\"Number of words not in model: \", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-634f63734488>:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  model.wv.index2entity[:10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find most frequent words \n",
    "# Ref: https://stackoverflow.com/questions/53621737/gensim-word2vec-retrieve-n-most-frequent-words\n",
    "model.wv.index2entity[:10]\n",
    "# It seems default ordering is sorted by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for w in list(model.vocab.keys()):\n",
    "    if w.isalpha() and w.islower() and len(w)<20:\n",
    "        words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words[:50000]\n",
    "for w in nec_words:\n",
    "    if w not in words and w in model:\n",
    "        words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {}\n",
    "for w in words:\n",
    "    data_dic[w] = model[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50128"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dic_to_gensim_bin_format(data_dic, file_name, path=\"../data/word_embeddings/\"):\n",
    "    vec_size = dim\n",
    "    m = gensim.models.keyedvectors.Word2VecKeyedVectors(vector_size=vec_size)\n",
    "    m.vocab = data_dic\n",
    "    m.vectors = np.array(list(data_dic.values()))\n",
    "    my_save_word2vec_format(binary=True, fname=path+file_name+'.bin', total_vec=len(data_dic), vocab=m.vocab, vectors=m.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\smart_open\\smart_open_lib.py:251: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  warnings.warn(\n",
      "<ipython-input-2-78eef57f9deb>:34: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  fout.write(utils.to_utf8(word) + b\" \" + row.tostring())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50128 300\n"
     ]
    }
   ],
   "source": [
    "save_dic_to_gensim_bin_format(data_dic, 'word2vec_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50024 300\n"
     ]
    }
   ],
   "source": [
    "save_dic_to_gensim_bin_format(data_dic, 'glove_50k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

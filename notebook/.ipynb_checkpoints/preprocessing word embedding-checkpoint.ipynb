{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import glob\n",
    "import gensim\n",
    "from gensim import utils\n",
    "from numpy import zeros, dtype, float32 as REAL, ascontiguousarray, fromstring\n",
    "import re\n",
    "import codecs\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>write dictionary to bin format</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://stackoverflow.com/questions/45981305/convert-python-dictionary-to-word2vec-object\n",
    "def my_save_word2vec_format(fname, vocab, vectors, binary=True, total_vec=2):\n",
    "    \"\"\"Store the input-hidden weight matrix in the same format used by the original\n",
    "    C word2vec-tool, for compatibility.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        The file path used to save the vectors in.\n",
    "    vocab : dict\n",
    "        The vocabulary of words.\n",
    "    vectors : numpy.array\n",
    "        The vectors to be stored.\n",
    "    binary : bool, optional\n",
    "        If True, the data wil be saved in binary word2vec format, else it will be saved in plain text.\n",
    "    total_vec : int, optional\n",
    "        Explicitly specify total number of vectors\n",
    "        (in case word vectors are appended with document vectors afterwards).\n",
    "\n",
    "    \"\"\"\n",
    "    if not (vocab or vectors):\n",
    "        raise RuntimeError(\"no input\")\n",
    "    if total_vec is None:\n",
    "        total_vec = len(vocab)\n",
    "    vector_size = vectors.shape[1]\n",
    "    assert (len(vocab), vector_size) == vectors.shape\n",
    "    with utils.smart_open(fname, 'wb') as fout:\n",
    "        print(total_vec, vector_size)\n",
    "        fout.write(utils.to_utf8(\"%s %s\\n\" % (total_vec, vector_size)))\n",
    "        # store in sorted order: most frequent words at the top\n",
    "        for word, row in vocab.items():\n",
    "            if binary:\n",
    "                row = row.astype(REAL)\n",
    "                fout.write(utils.to_utf8(word) + b\" \" + row.tostring())\n",
    "            else:\n",
    "                fout.write(utils.to_utf8(\"%s %s\\n\" % (word, ' '.join(repr(val) for val in row))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load word embedding model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/word_embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading word2vec embedding\n",
    "# Source link: https://code.google.com/archive/p/word2vec/\n",
    "model =  word2vec.KeyedVectors.load_word2vec_format(path+'./GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\smart_open\\smart_open_lib.py:251: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading Glove embedding\n",
    "# source: https://nlp.stanford.edu/projects/glove/\n",
    "# reformat glove embedding link: https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# convert to gensim format and save as txt file\n",
    "glove2word2vec(glove_input_file=path+\"glove.6B.300d.txt\", word2vec_output_file=path+\"gensim_glove_vectors.txt\")\n",
    "model = KeyedVectors.load_word2vec_format(path+\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya\\Anaconda3\\envs\\semantic\\lib\\site-packages\\smart_open\\smart_open_lib.py:251: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(path+\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of words\n",
    "len(list(model.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension of each word\n",
    "dim = model[\"he\"].shape[0]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.vocab.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary words \n",
    "nec_words = \"\"\n",
    "bias_words_path = \"../data/wordList/groups/en/\"\n",
    "\n",
    "for f in glob.glob(bias_words_path+\"*\"):\n",
    "    fi = open(f, \"r\")\n",
    "    nec_words = nec_words + ','.join(fi.readlines())\n",
    "    fi.close()\n",
    "\n",
    "target_words_path = \"../data/wordList/target/en/\"\n",
    "\n",
    "for f in glob.glob(target_words_path+\"*\"):\n",
    "    fi = open(f, \"r\")\n",
    "    nec_words = nec_words + ','.join(fi.readlines())\n",
    "    fi.close()    \n",
    "\n",
    "nec_words = nec_words.lower()\n",
    "tmp = re.split(r'[\\n\\t, ]+', nec_words)\n",
    "nec_words = [x for x in tmp if len(x)>0]\n",
    "\n",
    "# number of necessary words\n",
    "len(nec_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words not in model:  5\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for w in nec_words:\n",
    "    if w not in model:\n",
    "        cnt = cnt + 1\n",
    "print(\"Number of words not in model: \", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-634f63734488>:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  model.wv.index2entity[:10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find most frequent words \n",
    "# Ref: https://stackoverflow.com/questions/53621737/gensim-word2vec-retrieve-n-most-frequent-words\n",
    "model.wv.index2entity[:10]\n",
    "# It seems default ordering is sorted by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for w in list(model.vocab.keys()):\n",
    "    if w.isalpha() and w.islower() and len(w)<20:\n",
    "        words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words[:50000]\n",
    "for w in nec_words:\n",
    "    if w not in words and w in model:\n",
    "        words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {}\n",
    "for w in words:\n",
    "    data_dic[w] = model[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dic_to_gensim_bin_format(data_dic, file_name, path=\"../data/word_embeddings/\"):\n",
    "    vec_size = dim\n",
    "    m = gensim.models.keyedvectors.Word2VecKeyedVectors(vector_size=vec_size)\n",
    "    m.vocab = data_dic\n",
    "    m.vectors = np.array(list(data_dic.values()))\n",
    "    my_save_word2vec_format(binary=True, fname=path+file_name+'.bin', total_vec=len(data_dic), vocab=m.vocab, vectors=m.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50024 300\n"
     ]
    }
   ],
   "source": [
    "save_dic_to_gensim_bin_format(data_dic, 'glove_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

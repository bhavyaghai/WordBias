{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./word2vec.csv\",header=0, keep_default_na=False)\n",
    "#df = pd.read_csv(\"./word2vec_debiased.csv\",header=0, keep_default_na=False)\n",
    "path = \"../data/word_embeddings/\"\n",
    "model =  word2vec.KeyedVectors.load_word2vec_format(path+'word2vec_50k.bin', binary=True)\n",
    "#model =  word2vec.KeyedVectors.load_word2vec_format(path+'glove_50k.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word\n",
       "0    in\n",
       "1   for\n",
       "2  that\n",
       "3    is\n",
       "4    on"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"word\":list(model.vocab.keys())})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate bias direction when we have group of words not pairs\n",
    "def groupBiasDirection(gp1, gp2):\n",
    "    #print(gp1,gp2)\n",
    "    dim = len(model[\"he\"])\n",
    "    g1,g2 = np.zeros((dim,), dtype=float), np.zeros((dim,), dtype=float)\n",
    "    cnt = 0\n",
    "    for p in gp1:\n",
    "        p = p.strip()\n",
    "        if p not in model:\n",
    "            continue\n",
    "        p_vec = model[p]/norm(model[p])\n",
    "        g1 = np.add(g1,p_vec)\n",
    "        cnt += 1\n",
    "    print(\"count:  \", cnt)\n",
    "\n",
    "    cnt = 0\n",
    "    for q in gp2:\n",
    "        q = q.strip()\n",
    "        if q not in model:\n",
    "            continue\n",
    "        q_vec = model[q]/norm(model[q])\n",
    "        g2 = np.add(g2,q_vec) \n",
    "        cnt += 1\n",
    "    print(\"count 2:  \", cnt)\n",
    "    g1, g2 = g1/norm(g1), g2/norm(g2)\n",
    "    return (g1,g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruth True\n",
      "William True\n",
      "Horace True\n",
      "Mary True\n",
      "Susie True\n",
      "Amy True\n",
      "John True\n",
      "Henry True\n",
      "Edward True\n",
      "Elizabeth True\n"
     ]
    }
   ],
   "source": [
    "#y = \"tiffany,michelle,cindy,kristy,brad,eric,joey,billy\".split(\",\")\n",
    "y = \"Ruth, William, Horace, Mary, Susie, Amy, John, Henry, Edward, Elizabeth\".split(\",\")\n",
    "for w in y:\n",
    "    w = w.strip()\n",
    "    print(w, w in model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias = [\"he, son, his, him, father, man, boy, himself, male, brother, sons, fathers, men, boys, males, brothers, uncle, uncles, nephew, nephews\".split(\",\"),\n",
    "               \"she, daughter, hers, her, mother, woman, girl, herself, female, sister, daughters, mothers, women, girls, femen, sisters, aunt, aunts, niece, nieces\".split(\",\")]\n",
    "#eco_bias = [(\"rich\",\"wealthy\"),(\"poor\",\"impoverished\")]\n",
    "race_bias = [\"Alonzo, Jamel, Lerone, Percell, Theo, Alphonse, Jerome, Leroy, Rasaan, Torrance, Darnell,Lamar, Lionel, Rashaun, Tvree, Deion, Lamont, Malik, Terrence, Tyrone, Everol, Lavon, Marcellus, Terryl, Wardell,Aiesha, Lashelle, Nichelle, Shereen, Temeka, Ebony, Latisha, Shaniqua, Tameisha, Teretha, Jasmine, Latonya, Shanise,Tanisha, Tia, Lakisha, Latoya, Sharise, Tashika, Yolanda, Lashandra, Malika, Shavonn, Tawanda, Yvette\".split(\",\"),\n",
    "             \"Adam, Chip, Harry, Josh, Roger, Alan, Frank, Ian, Justin, Ryan, Andrew, Fred, Jack,Matthew, Stephen, Brad, Greg, Jed, Paul, Todd, Brandon, Hank, Jonathan, Peter, Wilbur, Amanda, Courtney, Heather,Melanie, Sara, Amber, Crystal, Katie, Meredith, Shannon, Betsy, Donna, Kristin, Nancy, Stephanie, Bobbie-Sue, Ellen,Lauren, Peggy, Sue-Ellen, Colleen, Emily, Megan, Rachel, Wendy\".split(\",\")]\n",
    "\n",
    "religion_bias = [\"baptism, messiah, catholicism, resurrection, christianity, salvation, protestant, gospel, trinity, jesus, christ, christian, cross, catholic, church\".split(\",\"),\n",
    "                \"allah, ramadan, turban, emir, salaam, sunni, koran, imam, sultan, prophet, veil, ayatollah, shiite, mosque, islam, sheik, muslim, muhammad\".split(\",\")]\n",
    "\n",
    "sentiment_bias = [\"caress, freedom, health, love, peace, cheer, friend, heaven, loyal, pleasure, diamond, gentle, honest, lucky, rainbow, diploma, gift, honor, miracle, sunrise, family, happy, laughter, paradise, vacation\".split(\",\"),\n",
    "                 \"abuse, crash, filth, murder, sickness, accident, death, grief, poison, stink, assault, disaster, hatred, pollute, tragedy, divorce, jail, poverty, ugly, cancer, kill, rotten, vomit, agony, prison\".split(\",\")]\n",
    "\n",
    "age_bias = [\"Taylor, Jamie, Daniel, Aubrey, Alison, Miranda, Jacob, Arthur, Aaron, Ethan\".split(\",\"),\n",
    "           \"Ruth, William, Horace, Mary, Susie, Amy, John, Henry, Edward, Elizabeth\".split(\",\")]\n",
    "\n",
    "eco_bias = [\"rich,richer,richest,affluence,advantaged,wealthy,costly,exorbitant,expensive,exquisite,extravagant,flush,invaluable,lavish,luxuriant,luxurious,luxury,moneyed,opulent,plush,precious,priceless,privileged,prosperous,classy\".split(\",\"),\n",
    "           \"poor,poorer,poorest,poverty,destitude,needy,impoverished,economical,inexpensive,ruined,cheap,penurious,underprivileged,penniless,valueless,penury,indigence,bankrupt,beggarly,moneyless,insolvent\".split(\",\")]\n",
    "\n",
    "bias_words = {\"gender\":gender_bias, \"religion\":religion_bias, \"race\":race_bias, \"age\":age_bias, \"sentiment\":sentiment_bias, \"economic\":eco_bias}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "femen\n",
      "Tvree\n",
      "Everol\n",
      "Teretha\n",
      "Shavonn\n",
      "Bobbie-Sue\n",
      "Sue-Ellen\n",
      "destitude\n",
      "penurious\n",
      "indigence\n",
      "beggarly\n",
      "moneyless\n"
     ]
    }
   ],
   "source": [
    "for bias_type in bias_words:\n",
    "    for words in bias_words[bias_type]:\n",
    "        for w in words:\n",
    "            w = w.strip()\n",
    "            if w not in model:\n",
    "                print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': [['he',\n",
       "   ' son',\n",
       "   ' his',\n",
       "   ' him',\n",
       "   ' father',\n",
       "   ' man',\n",
       "   ' boy',\n",
       "   ' himself',\n",
       "   ' male',\n",
       "   ' brother',\n",
       "   ' sons',\n",
       "   ' fathers',\n",
       "   ' men',\n",
       "   ' boys',\n",
       "   ' males',\n",
       "   ' brothers',\n",
       "   ' uncle',\n",
       "   ' uncles',\n",
       "   ' nephew',\n",
       "   ' nephews'],\n",
       "  ['she',\n",
       "   ' daughter',\n",
       "   ' hers',\n",
       "   ' her',\n",
       "   ' mother',\n",
       "   ' woman',\n",
       "   ' girl',\n",
       "   ' herself',\n",
       "   ' female',\n",
       "   ' sister',\n",
       "   ' daughters',\n",
       "   ' mothers',\n",
       "   ' women',\n",
       "   ' girls',\n",
       "   ' femen',\n",
       "   ' sisters',\n",
       "   ' aunt',\n",
       "   ' aunts',\n",
       "   ' niece',\n",
       "   ' nieces']],\n",
       " 'religion': [['baptism',\n",
       "   ' messiah',\n",
       "   ' catholicism',\n",
       "   ' resurrection',\n",
       "   ' christianity',\n",
       "   ' salvation',\n",
       "   ' protestant',\n",
       "   ' gospel',\n",
       "   ' trinity',\n",
       "   ' jesus',\n",
       "   ' christ',\n",
       "   ' christian',\n",
       "   ' cross',\n",
       "   ' catholic',\n",
       "   ' church'],\n",
       "  ['allah',\n",
       "   ' ramadan',\n",
       "   ' turban',\n",
       "   ' emir',\n",
       "   ' salaam',\n",
       "   ' sunni',\n",
       "   ' koran',\n",
       "   ' imam',\n",
       "   ' sultan',\n",
       "   ' prophet',\n",
       "   ' veil',\n",
       "   ' ayatollah',\n",
       "   ' shiite',\n",
       "   ' mosque',\n",
       "   ' islam',\n",
       "   ' sheik',\n",
       "   ' muslim',\n",
       "   ' muhammad']],\n",
       " 'race': [['Alonzo',\n",
       "   ' Jamel',\n",
       "   ' Lerone',\n",
       "   ' Percell',\n",
       "   ' Theo',\n",
       "   ' Alphonse',\n",
       "   ' Jerome',\n",
       "   ' Leroy',\n",
       "   ' Rasaan',\n",
       "   ' Torrance',\n",
       "   ' Darnell',\n",
       "   'Lamar',\n",
       "   ' Lionel',\n",
       "   ' Rashaun',\n",
       "   ' Tvree',\n",
       "   ' Deion',\n",
       "   ' Lamont',\n",
       "   ' Malik',\n",
       "   ' Terrence',\n",
       "   ' Tyrone',\n",
       "   ' Everol',\n",
       "   ' Lavon',\n",
       "   ' Marcellus',\n",
       "   ' Terryl',\n",
       "   ' Wardell',\n",
       "   'Aiesha',\n",
       "   ' Lashelle',\n",
       "   ' Nichelle',\n",
       "   ' Shereen',\n",
       "   ' Temeka',\n",
       "   ' Ebony',\n",
       "   ' Latisha',\n",
       "   ' Shaniqua',\n",
       "   ' Tameisha',\n",
       "   ' Teretha',\n",
       "   ' Jasmine',\n",
       "   ' Latonya',\n",
       "   ' Shanise',\n",
       "   'Tanisha',\n",
       "   ' Tia',\n",
       "   ' Lakisha',\n",
       "   ' Latoya',\n",
       "   ' Sharise',\n",
       "   ' Tashika',\n",
       "   ' Yolanda',\n",
       "   ' Lashandra',\n",
       "   ' Malika',\n",
       "   ' Shavonn',\n",
       "   ' Tawanda',\n",
       "   ' Yvette'],\n",
       "  ['Adam',\n",
       "   ' Chip',\n",
       "   ' Harry',\n",
       "   ' Josh',\n",
       "   ' Roger',\n",
       "   ' Alan',\n",
       "   ' Frank',\n",
       "   ' Ian',\n",
       "   ' Justin',\n",
       "   ' Ryan',\n",
       "   ' Andrew',\n",
       "   ' Fred',\n",
       "   ' Jack',\n",
       "   'Matthew',\n",
       "   ' Stephen',\n",
       "   ' Brad',\n",
       "   ' Greg',\n",
       "   ' Jed',\n",
       "   ' Paul',\n",
       "   ' Todd',\n",
       "   ' Brandon',\n",
       "   ' Hank',\n",
       "   ' Jonathan',\n",
       "   ' Peter',\n",
       "   ' Wilbur',\n",
       "   ' Amanda',\n",
       "   ' Courtney',\n",
       "   ' Heather',\n",
       "   'Melanie',\n",
       "   ' Sara',\n",
       "   ' Amber',\n",
       "   ' Crystal',\n",
       "   ' Katie',\n",
       "   ' Meredith',\n",
       "   ' Shannon',\n",
       "   ' Betsy',\n",
       "   ' Donna',\n",
       "   ' Kristin',\n",
       "   ' Nancy',\n",
       "   ' Stephanie',\n",
       "   ' Bobbie-Sue',\n",
       "   ' Ellen',\n",
       "   'Lauren',\n",
       "   ' Peggy',\n",
       "   ' Sue-Ellen',\n",
       "   ' Colleen',\n",
       "   ' Emily',\n",
       "   ' Megan',\n",
       "   ' Rachel',\n",
       "   ' Wendy']],\n",
       " 'age': [['Taylor',\n",
       "   ' Jamie',\n",
       "   ' Daniel',\n",
       "   ' Aubrey',\n",
       "   ' Alison',\n",
       "   ' Miranda',\n",
       "   ' Jacob',\n",
       "   ' Arthur',\n",
       "   ' Aaron',\n",
       "   ' Ethan'],\n",
       "  ['Ruth',\n",
       "   ' William',\n",
       "   ' Horace',\n",
       "   ' Mary',\n",
       "   ' Susie',\n",
       "   ' Amy',\n",
       "   ' John',\n",
       "   ' Henry',\n",
       "   ' Edward',\n",
       "   ' Elizabeth']],\n",
       " 'sentiment': [['caress',\n",
       "   ' freedom',\n",
       "   ' health',\n",
       "   ' love',\n",
       "   ' peace',\n",
       "   ' cheer',\n",
       "   ' friend',\n",
       "   ' heaven',\n",
       "   ' loyal',\n",
       "   ' pleasure',\n",
       "   ' diamond',\n",
       "   ' gentle',\n",
       "   ' honest',\n",
       "   ' lucky',\n",
       "   ' rainbow',\n",
       "   ' diploma',\n",
       "   ' gift',\n",
       "   ' honor',\n",
       "   ' miracle',\n",
       "   ' sunrise',\n",
       "   ' family',\n",
       "   ' happy',\n",
       "   ' laughter',\n",
       "   ' paradise',\n",
       "   ' vacation'],\n",
       "  ['abuse',\n",
       "   ' crash',\n",
       "   ' filth',\n",
       "   ' murder',\n",
       "   ' sickness',\n",
       "   ' accident',\n",
       "   ' death',\n",
       "   ' grief',\n",
       "   ' poison',\n",
       "   ' stink',\n",
       "   ' assault',\n",
       "   ' disaster',\n",
       "   ' hatred',\n",
       "   ' pollute',\n",
       "   ' tragedy',\n",
       "   ' divorce',\n",
       "   ' jail',\n",
       "   ' poverty',\n",
       "   ' ugly',\n",
       "   ' cancer',\n",
       "   ' kill',\n",
       "   ' rotten',\n",
       "   ' vomit',\n",
       "   ' agony',\n",
       "   ' prison']],\n",
       " 'economic': [['rich',\n",
       "   'richer',\n",
       "   'richest',\n",
       "   'affluence',\n",
       "   'advantaged',\n",
       "   'wealthy',\n",
       "   'costly',\n",
       "   'exorbitant',\n",
       "   'expensive',\n",
       "   'exquisite',\n",
       "   'extravagant',\n",
       "   'flush',\n",
       "   'invaluable',\n",
       "   'lavish',\n",
       "   'luxuriant',\n",
       "   'luxurious',\n",
       "   'luxury',\n",
       "   'moneyed',\n",
       "   'opulent',\n",
       "   'plush',\n",
       "   'precious',\n",
       "   'priceless',\n",
       "   'privileged',\n",
       "   'prosperous',\n",
       "   'classy'],\n",
       "  ['poor',\n",
       "   'poorer',\n",
       "   'poorest',\n",
       "   'poverty',\n",
       "   'destitude',\n",
       "   'needy',\n",
       "   'impoverished',\n",
       "   'economical',\n",
       "   'inexpensive',\n",
       "   'ruined',\n",
       "   'cheap',\n",
       "   'penurious',\n",
       "   'underprivileged',\n",
       "   'penniless',\n",
       "   'valueless',\n",
       "   'penury',\n",
       "   'indigence',\n",
       "   'bankrupt',\n",
       "   'beggarly',\n",
       "   'moneyless',\n",
       "   'insolvent']]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 21\n",
      "count:   25\n",
      "count 2:   16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.78580765e-02,  6.28788750e-02, -7.58523189e-02,  8.23152863e-02,\n",
       "        -8.12157068e-03,  1.50427927e-02,  5.77271445e-02, -1.04631918e-01,\n",
       "         1.88045927e-02,  1.02404768e-01, -4.43742886e-02, -6.68432025e-02,\n",
       "         6.58769741e-02,  6.59164354e-02, -6.07808446e-02,  5.80716808e-02,\n",
       "         6.77600382e-02,  7.79177848e-02, -1.45713756e-02,  7.54993673e-02,\n",
       "        -2.82500729e-02, -3.32781611e-02,  2.70306636e-02,  5.92220398e-02,\n",
       "         8.74367768e-02,  3.71204847e-02, -3.15904487e-02,  6.44700915e-02,\n",
       "        -1.30680923e-02, -8.72942017e-02,  1.43666752e-02,  5.38476242e-02,\n",
       "         5.10431656e-02,  6.44515648e-02, -9.05238009e-03, -7.60298711e-02,\n",
       "         2.59919222e-02, -5.14201954e-02, -3.44416449e-02,  6.51286755e-03,\n",
       "         1.26016070e-01,  1.95617793e-02,  7.98833217e-02, -2.75324395e-02,\n",
       "         7.20531414e-02, -7.87375146e-02, -1.52603195e-02,  1.61302715e-01,\n",
       "        -4.23355790e-02, -2.97217172e-02,  7.51155594e-02,  3.75476783e-02,\n",
       "         3.34649931e-02, -8.88825240e-02, -9.07708946e-02,  4.85430837e-02,\n",
       "        -6.94795931e-02, -9.83704034e-02,  5.44465407e-02, -4.04029802e-02,\n",
       "         5.69485747e-03,  2.88317843e-02, -1.32374227e-01, -6.61746414e-02,\n",
       "         3.35049623e-02, -5.48956556e-02, -9.95334350e-02,  2.14537293e-02,\n",
       "         8.73309965e-03,  2.51012115e-02,  1.13498154e-01, -3.55524709e-02,\n",
       "         3.12694377e-02, -3.53779915e-03, -4.22368177e-02, -1.20191437e-02,\n",
       "        -1.17206262e-02,  8.69125634e-02,  8.14803395e-03,  6.59677040e-02,\n",
       "        -7.23219211e-02,  2.50450650e-02, -1.02553623e-01,  4.41891438e-02,\n",
       "        -6.35943436e-02, -2.46041156e-02, -5.95473311e-02,  5.76293127e-02,\n",
       "         1.05221608e-02,  5.41085679e-02, -1.51232655e-02,  7.45221282e-03,\n",
       "        -5.46314758e-02, -1.41894183e-02, -9.80787362e-02, -8.03623602e-02,\n",
       "         3.02999470e-02, -1.89636598e-02,  2.32971686e-02, -7.46949154e-02,\n",
       "        -4.95265630e-02,  3.10106654e-02,  5.05631982e-02,  4.06993982e-03,\n",
       "        -1.82364100e-02, -2.08771867e-02,  1.22384363e-01,  6.20214325e-02,\n",
       "         6.44905596e-02, -9.14495878e-02,  2.05375780e-03,  6.91448113e-02,\n",
       "         6.38431225e-03, -2.82612154e-03,  1.32172330e-01, -3.98656810e-02,\n",
       "         7.25763418e-02, -9.03082899e-02,  5.07482391e-02,  5.65650618e-02,\n",
       "        -1.83005555e-03, -7.47730622e-03,  5.06185509e-02, -1.24832135e-04,\n",
       "        -4.05294342e-02,  2.36791359e-02,  2.15531297e-02, -6.89529589e-02,\n",
       "         8.84712235e-02,  8.83088763e-03, -1.72251805e-02,  5.57215820e-02,\n",
       "         3.58093377e-03,  5.49932065e-02, -2.77479554e-02, -3.63589499e-02,\n",
       "         6.43824027e-03,  6.53115380e-02, -3.50563455e-02,  1.05197069e-01,\n",
       "        -2.69407968e-02, -1.04401453e-01, -1.38319948e-02,  5.08112580e-02,\n",
       "         1.13025182e-01, -4.08393449e-03, -1.25515231e-03,  9.95958162e-02,\n",
       "        -4.58858050e-03, -3.87784346e-02,  7.23222476e-02,  6.22375634e-02,\n",
       "         1.41935814e-02, -1.32978323e-03,  2.12269272e-03, -2.11511267e-02,\n",
       "        -7.43481915e-02, -1.50087726e-02, -7.71560316e-02, -1.18412742e-01,\n",
       "        -9.79914864e-02, -1.09106938e-02,  4.82174458e-02,  1.11895702e-02,\n",
       "         6.16252421e-03, -1.92230579e-02,  3.89286599e-02, -7.22064160e-02,\n",
       "        -1.00860388e-01,  4.64716275e-02, -1.42416525e-01, -1.75951006e-04,\n",
       "        -6.20124204e-02, -5.10081355e-02, -9.29598006e-03,  5.96481818e-03,\n",
       "        -2.96183304e-02, -1.11847669e-02, -7.35238899e-02, -1.47567944e-02,\n",
       "        -2.91535496e-02, -1.79854786e-02, -6.08463216e-02, -3.02360830e-02,\n",
       "        -5.92873845e-02, -1.18613109e-02,  3.62423798e-02, -7.91162657e-04,\n",
       "         1.33788828e-02, -6.51200798e-02, -1.53441838e-02, -2.11027557e-02,\n",
       "         7.99046960e-02, -1.63097443e-03, -1.02835542e-01,  3.91400489e-02,\n",
       "        -5.36951664e-02,  8.57230962e-03,  2.37044939e-02, -5.17327842e-02,\n",
       "         3.97452142e-02,  8.06443327e-02, -2.76282713e-02, -7.52846138e-02,\n",
       "        -1.83108460e-02, -6.88167442e-03, -2.58141147e-02, -8.24607830e-02,\n",
       "        -1.16827739e-01, -1.25773804e-02, -1.10357801e-01,  5.71829061e-02,\n",
       "         3.72778647e-02,  2.34493194e-02,  8.05900766e-02,  9.54806984e-02,\n",
       "        -3.70056424e-03,  1.07089069e-01, -1.74001051e-02,  2.73885477e-02,\n",
       "         5.10841100e-02,  5.67788511e-02, -6.27704426e-02,  1.34075500e-02,\n",
       "         5.10274207e-02,  5.51792135e-02,  1.26160333e-01, -1.73327497e-02,\n",
       "        -4.01975473e-02,  3.42574421e-02, -1.71149227e-02, -1.08339900e-02,\n",
       "        -1.77652697e-04,  1.64958621e-02,  9.99255818e-02, -4.42337795e-03,\n",
       "        -2.24798097e-02, -6.30777493e-02,  5.76734756e-02, -6.86709495e-02,\n",
       "         7.26315416e-02, -1.13347561e-01,  1.84692734e-03, -2.69155444e-02,\n",
       "         2.17291914e-03,  1.79714275e-02,  4.89767239e-02, -6.03221733e-02,\n",
       "        -2.57594833e-02, -3.66819729e-02,  7.47092661e-02,  6.41140264e-02,\n",
       "         8.69751618e-02,  7.75103912e-02, -2.57099801e-02, -5.38048935e-02,\n",
       "        -9.91444832e-02, -4.81215471e-02, -8.24607905e-02,  1.29880709e-02,\n",
       "         1.43324976e-02, -4.57444095e-03, -1.46794379e-02,  7.22164858e-02,\n",
       "         4.58843338e-02,  1.78074137e-02, -1.28451715e-01, -1.05787423e-01,\n",
       "        -4.65589995e-02,  2.52573910e-02, -7.35689801e-02,  1.00500554e-01,\n",
       "        -3.23431001e-02,  2.17872434e-02,  1.60588334e-02, -5.37191241e-02,\n",
       "         2.07450958e-02, -1.19754523e-02, -7.43469359e-02,  1.08064691e-01,\n",
       "         1.87893456e-02, -4.06042250e-02, -3.15632298e-02, -4.20496298e-02,\n",
       "        -4.58237215e-02,  1.08261474e-01, -4.35342687e-02,  1.90104308e-02,\n",
       "         8.02025309e-02, -2.68877241e-02, -4.67664779e-02, -5.58377842e-02,\n",
       "        -6.12036057e-02,  2.46424081e-03, -1.27699396e-02, -2.55185174e-02,\n",
       "        -1.71449782e-02, -3.86063799e-02,  8.90776128e-03, -5.80349436e-03]),\n",
       " array([ 7.03051599e-02,  2.32344383e-02, -4.82189272e-02,  1.02693436e-01,\n",
       "        -1.40731384e-02,  1.33604430e-01,  3.22783762e-02,  3.86150983e-03,\n",
       "         6.55282383e-02,  4.83068622e-02,  1.29846202e-02, -2.77816164e-02,\n",
       "         6.73637006e-02,  1.02735280e-01, -6.93312030e-02,  5.90892943e-02,\n",
       "         6.09705701e-02,  1.06686102e-01,  4.59570340e-04,  3.67490963e-02,\n",
       "         6.64880002e-02, -7.33321856e-03,  9.96380360e-02, -1.06313784e-02,\n",
       "         9.55505917e-02, -3.21343098e-02, -9.50300449e-02,  8.63930951e-04,\n",
       "         2.20456165e-02, -9.88329062e-02, -8.89578181e-02, -4.55326421e-02,\n",
       "         4.36623363e-02,  3.54427690e-02, -4.74032748e-03,  3.07737565e-02,\n",
       "        -1.79122681e-02, -6.70782485e-02, -4.56484517e-02,  7.31391555e-02,\n",
       "         3.58653075e-02,  3.65168854e-02,  1.02664119e-01, -6.04338293e-02,\n",
       "         6.56151048e-02, -5.20599974e-02, -4.83781015e-02,  7.59777220e-02,\n",
       "        -6.72548603e-02,  1.45863904e-02,  4.74403599e-02, -1.77439720e-02,\n",
       "        -1.77740855e-02, -8.05076646e-02, -7.32757778e-02, -8.93889001e-02,\n",
       "        -1.45658679e-01, -8.24374938e-02, -2.55522429e-02, -3.24831042e-02,\n",
       "         5.90415690e-02,  2.45824289e-02, -1.09711822e-01, -2.33739126e-02,\n",
       "         4.39296292e-02, -1.23761201e-01, -6.22679977e-02,  3.08146201e-02,\n",
       "        -2.24919042e-02, -5.37077988e-02,  2.31417946e-02, -5.39793289e-02,\n",
       "        -1.10242465e-02,  3.25875983e-02, -2.66192023e-02, -4.43594121e-02,\n",
       "        -3.67580704e-02,  8.41755718e-02,  2.79490421e-02,  4.18569484e-02,\n",
       "        -6.23783974e-04,  3.99656114e-02, -1.28645336e-01,  8.04205923e-02,\n",
       "        -6.07735338e-02,  5.33353861e-02, -1.57224781e-02,  5.06075100e-02,\n",
       "         3.80994374e-02, -2.27458296e-02, -2.74819939e-02, -1.17293578e-02,\n",
       "        -4.64600842e-02, -9.76308128e-02, -7.55996037e-02, -3.03857363e-02,\n",
       "         8.49093950e-02, -2.24570900e-02,  2.31074611e-02, -3.19944806e-02,\n",
       "         4.16674620e-03,  6.04394138e-02, -4.36090534e-02,  2.76457432e-02,\n",
       "        -8.54568805e-02, -2.44435505e-02,  3.40392862e-02, -8.18122712e-03,\n",
       "         6.34824959e-02, -6.71294391e-02,  5.06272697e-03,  3.84138740e-02,\n",
       "        -2.71827328e-02, -3.14772366e-02,  7.30725035e-02,  2.66591497e-02,\n",
       "         6.67661558e-02, -8.79237438e-02,  3.86105526e-02,  9.83769464e-02,\n",
       "        -6.73586441e-02,  3.02435115e-02, -8.34906237e-02, -8.14501322e-02,\n",
       "        -7.54834508e-02,  1.85804362e-02, -3.72352364e-02, -5.80882112e-02,\n",
       "         1.63868155e-03, -8.56813377e-02, -1.54119342e-02,  2.87361845e-02,\n",
       "        -4.39461886e-02,  4.05803956e-02, -5.30504731e-02, -3.13562257e-03,\n",
       "        -3.09834252e-02, -1.16045667e-02, -3.15180729e-02,  7.28831713e-02,\n",
       "         1.76549738e-02, -1.12197822e-01,  7.21130043e-02,  1.26519940e-01,\n",
       "         3.62007450e-02, -1.72011229e-02, -7.34179103e-02,  2.44786716e-02,\n",
       "         6.30357163e-03, -1.82768775e-02,  8.00671810e-02, -4.50008019e-02,\n",
       "         2.61233693e-03,  4.64557451e-02, -1.24605078e-02,  8.96655140e-03,\n",
       "        -1.00884154e-01,  2.17762812e-03, -3.73261075e-02, -1.17737090e-01,\n",
       "        -8.72682521e-02,  4.70455541e-02, -4.46798463e-03,  4.05482599e-02,\n",
       "         6.38711376e-03, -3.16673605e-02,  4.76258804e-02, -4.01272853e-02,\n",
       "        -1.16276911e-02, -7.40558584e-02, -1.03579993e-01, -2.04576679e-04,\n",
       "        -8.56906918e-02, -6.78080847e-02,  7.03573089e-03,  7.85731419e-03,\n",
       "         4.79861378e-02, -8.73962800e-02, -7.68613404e-03,  5.58107035e-02,\n",
       "        -8.01344712e-02, -1.32415371e-01, -2.15803212e-02,  6.20642669e-02,\n",
       "        -4.98072814e-02, -1.20051774e-02, -3.12660651e-02,  7.12048814e-02,\n",
       "         3.71475169e-02,  4.86990442e-02, -5.12984283e-02,  5.34319113e-03,\n",
       "         5.99781679e-02, -2.39955392e-02, -4.12482846e-02,  8.27830903e-03,\n",
       "        -8.37070654e-03, -2.93211204e-02,  3.97773422e-02, -2.96505815e-02,\n",
       "        -2.34916961e-02,  6.02910318e-02,  1.50326851e-02, -1.19243010e-01,\n",
       "        -1.95558312e-02, -5.00435813e-02, -1.83592423e-02, -2.78202138e-02,\n",
       "        -1.01512016e-01, -6.76279660e-02, -2.10998818e-02,  9.09659737e-03,\n",
       "         6.62629550e-02,  4.43009088e-02,  7.46919168e-02,  6.22908923e-02,\n",
       "         3.14445431e-02,  7.22564131e-02, -6.15852493e-02,  2.95276497e-02,\n",
       "         2.81734102e-02,  4.24383239e-02, -3.43492155e-02,  1.01448667e-01,\n",
       "         5.01451889e-02, -1.56152239e-02,  4.86167983e-02, -3.39023148e-02,\n",
       "        -4.32759924e-02,  3.08468236e-02,  6.61584178e-02,  5.91149091e-02,\n",
       "         8.89471096e-02, -6.14849224e-03,  2.46713466e-02, -2.64596537e-02,\n",
       "         5.69824840e-02, -9.69571132e-02,  5.62709136e-02, -3.77222099e-02,\n",
       "         6.33215931e-02, -1.06003323e-01, -2.85695602e-02, -4.34221307e-02,\n",
       "        -3.00851975e-02,  5.44836488e-02,  5.69837116e-02, -9.27392526e-02,\n",
       "        -2.29323300e-02, -7.93993659e-02,  6.01562300e-02, -7.47293704e-02,\n",
       "         5.86786069e-02,  8.67898060e-02,  1.94335964e-02, -1.02321934e-01,\n",
       "         3.05536397e-02, -1.10133327e-02, -5.92859725e-03, -1.26969946e-04,\n",
       "        -3.76033016e-02, -1.85795103e-02,  6.78050674e-02,  3.73775782e-02,\n",
       "        -8.78171194e-03,  3.02320886e-02, -1.02947817e-01, -5.90585541e-02,\n",
       "        -2.79614053e-02, -5.84897030e-02, -5.40098749e-02,  9.45412577e-02,\n",
       "         4.98434543e-03, -1.03944728e-02, -2.10069609e-02, -3.74395943e-02,\n",
       "        -8.63918279e-03, -5.31891856e-02, -8.09716920e-02,  2.96855788e-02,\n",
       "         1.42025173e-02, -2.24693668e-02,  4.70998410e-02,  3.85435469e-02,\n",
       "        -8.82848199e-02,  7.85680295e-02, -1.46017224e-02,  9.98398252e-02,\n",
       "         5.30577136e-02, -4.56485397e-02, -5.38133674e-02,  1.07518070e-02,\n",
       "        -1.70902485e-01, -1.33074795e-02, -1.71668270e-02,  9.04262587e-02,\n",
       "        -8.77035081e-02, -1.24987622e-02,  6.92585050e-02,  1.06810402e-02]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify how many words for each bias type are actually being used to compute average vector\n",
    "t = \"economic\"\n",
    "print(len(bias_words[t][0]), len(bias_words[t][1])) \n",
    "bias_w = bias_words[t]\n",
    "groupBiasDirection(bias_w[0], bias_w[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:   20\n",
      "count 2:   19\n",
      "count:   15\n",
      "count 2:   18\n",
      "count:   46\n",
      "count 2:   48\n",
      "count:   10\n",
      "count 2:   10\n",
      "count:   25\n",
      "count 2:   25\n",
      "count:   25\n",
      "count 2:   16\n"
     ]
    }
   ],
   "source": [
    "all_words = list(model.vocab.keys()) #[:50000]\n",
    "#all_words = df[\"word\"].tolist()\n",
    "df = pd.DataFrame({\"word\":all_words})\n",
    "for bias_type in bias_words:\n",
    "    bias_w = bias_words[bias_type]\n",
    "    df[bias_type] = None\n",
    "    g1, g2 = groupBiasDirection(bias_w[0], bias_w[1])\n",
    "    for index, row in df.iterrows():\n",
    "        w = row[\"word\"]\n",
    "        # assuming group bias \"Quantification algo\"\n",
    "        df.at[index, bias_type] = round(cosine(g1,model[w])-cosine(g2,model[w]),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender:  -0.2914 0.3362\n",
      "Sentiment:  -0.3683 0.3651\n",
      "Race:  -0.3131 0.3645\n",
      "Religion:  -0.3848 0.4055\n",
      "Age:  -0.2712 0.3126\n",
      "Economic:  -0.4324 0.391\n"
     ]
    }
   ],
   "source": [
    "gen_max, gen_min = df[\"gender\"].max(), df[\"gender\"].min()\n",
    "sen_max, sen_min = df[\"sentiment\"].max(), df[\"sentiment\"].min()\n",
    "race_max, race_min = df[\"race\"].max(), df[\"race\"].min()\n",
    "relg_max, relg_min = df[\"religion\"].max(), df[\"religion\"].min()\n",
    "age_max, age_min = df[\"age\"].max(), df[\"age\"].min()\n",
    "eco_max, eco_min = df[\"economic\"].max(), df[\"economic\"].min()\n",
    "\n",
    "print(\"Gender: \",gen_min,gen_max)\n",
    "print(\"Sentiment: \",sen_min, sen_max)\n",
    "print(\"Race: \",race_min, race_max)\n",
    "print(\"Religion: \",relg_min, relg_max)\n",
    "print(\"Age: \",age_min, age_max)\n",
    "print(\"Economic: \",eco_min, eco_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while calculating for negative values we want the range to be [-1, 0] instead of [0,1]\n",
    "# so, we have used 'negative' parameter to flip the sign if negative values are fed \n",
    "def percentile_rank(values, col, negative=False):\n",
    "    N = len(values)\n",
    "    last_ind = -1\n",
    "    for i,items in enumerate(values.iteritems()): \n",
    "        index, val = items[0], items[1]\n",
    "        if last_ind!=-1 and val==df.at[last_ind, col]: \n",
    "            df.at[index, col] = df.at[last_ind, col] \n",
    "            #percentile.append(percentile[i-1])\n",
    "        else:\n",
    "            p = (N-i)/N\n",
    "            #print(i,p)\n",
    "            df.at[index, col] = p \n",
    "            #percentile.append(p)\n",
    "        if negative:\n",
    "            df.at[index, col] = df.at[index, col]*-1\n",
    "        last_ind = index\n",
    "\n",
    "for col in df.columns:\n",
    "    if col==\"word\":\n",
    "        continue\n",
    "    values = df.loc[df[col]>0][col].sort_values(ascending=False, inplace=False)\n",
    "    percentile_rank(values, col)\n",
    "    \n",
    "    values = df.loc[df[col]<0][col].sort_values(ascending=True, inplace=False)\n",
    "    percentile_rank(values, col, negative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.4\n",
       "1    1.0\n",
       "2    0.2\n",
       "3   -0.8\n",
       "4    0.6\n",
       "5   -1.0\n",
       "6    0.4\n",
       "7    0.6\n",
       "8    0.8\n",
       "9   -0.6\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more modular percentile_rank function\n",
    "def percentile_rank(values, negative=False):\n",
    "    out = values.copy()\n",
    "    N = len(values)\n",
    "    last_ind = -1\n",
    "    for i,items in enumerate(values.iteritems()):\n",
    "        index, val = items[0], items[1]\n",
    "        if last_ind!=-1 and val==values.get(last_ind): \n",
    "            out.at[index] = out.get(last_ind)\n",
    "            #print(\"last_ind: \",last_ind,\"  index: \",index, \" p: \",out.get(last_ind))\n",
    "        else:\n",
    "            p = (N-i)/N\n",
    "            out.at[index] = p\n",
    "            #print(\"index: \",index, \" p: \",p)\n",
    "        if negative:\n",
    "            out.at[index] = out.get(index)*-1\n",
    "        last_ind = index\n",
    "    return out\n",
    "\n",
    "arr = pd.Series([-1,7,1,-4,2,-7,-1,2,5,-2], dtype='float')\n",
    "values = arr[arr>0].sort_values(ascending=False, inplace=False)\n",
    "res1 = percentile_rank(values, negative=False)\n",
    "\n",
    "values = arr[arr<=0].sort_values(ascending=True, inplace=False)\n",
    "res2 = percentile_rank(values, negative=True)\n",
    "res = pd.concat([res1,res2])\n",
    "res = res.reindex(arr.index)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.4, 1.0, 0.2, -0.8, 0.6, -1.0, 0.4, 0.6, 0.8, -0.6]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender:  -0.2914 0.3362\n",
      "Sentiment:  -0.3683 0.3651\n",
      "Race:  -0.3131 0.3645\n",
      "Religion:  -0.3848 0.4055\n",
      "Age:  -0.2712 0.3126\n",
      "Economic:  -0.4324 0.391\n"
     ]
    }
   ],
   "source": [
    "gen_max, gen_min = df[\"gender\"].max(), df[\"gender\"].min()\n",
    "sen_max, sen_min = df[\"sentiment\"].max(), df[\"sentiment\"].min()\n",
    "race_max, race_min = df[\"race\"].max(), df[\"race\"].min()\n",
    "relg_max, relg_min = df[\"religion\"].max(), df[\"religion\"].min()\n",
    "age_max, age_min = df[\"age\"].max(), df[\"age\"].min()\n",
    "eco_max, eco_min = df[\"economic\"].max(), df[\"economic\"].min()\n",
    "\n",
    "print(\"Gender: \",gen_min,gen_max)\n",
    "print(\"Sentiment: \",sen_min, sen_max)\n",
    "print(\"Race: \",race_min, race_max)\n",
    "print(\"Religion: \",relg_min, relg_max)\n",
    "print(\"Age: \",age_min, age_max)\n",
    "print(\"Economic: \",eco_min, eco_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of bias scores\n",
    "for index, row in df.iterrows():    \n",
    "    if row[\"gender\"]>0:\n",
    "        df.at[index, \"gender\"] = row[\"gender\"]/gen_max\n",
    "    else:\n",
    "        df.at[index, \"gender\"] = -1*row[\"gender\"]/gen_min\n",
    "        \n",
    "    if row[\"race\"]>0:\n",
    "        df.at[index, \"race\"] = row[\"race\"]/race_max\n",
    "    else:\n",
    "        df.at[index, \"race\"] = -1*row[\"race\"]/race_min\n",
    "    \n",
    "    if row[\"sentiment\"]>0:\n",
    "        df.at[index, \"sentiment\"] = row[\"sentiment\"]/sen_max\n",
    "    else:\n",
    "        df.at[index, \"sentiment\"] = -1*row[\"sentiment\"]/sen_min\n",
    "        \n",
    "    if row[\"religion\"]>0:\n",
    "        df.at[index, \"religion\"] = row[\"religion\"]/relg_max\n",
    "    else:\n",
    "        df.at[index, \"religion\"] = -1*row[\"religion\"]/relg_min\n",
    "    \n",
    "    if row[\"age\"]>0:\n",
    "        df.at[index, \"age\"] = row[\"age\"]/age_max\n",
    "    else:\n",
    "        df.at[index, \"age\"] = -1*row[\"age\"]/age_min  \n",
    "    \n",
    "    if row[\"economic\"]>0:\n",
    "        df.at[index, \"economic\"] = row[\"economic\"]/eco_max\n",
    "    else:\n",
    "        df.at[index, \"economic\"] = -1*row[\"economic\"]/eco_min  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender:  -1.0 1.0\n",
      "Sentiment:  -1.0 1.0\n",
      "Race:  -1.0 1.0\n",
      "Religion:  -1.0 1.0\n",
      "Age:  -1.0 1.0\n",
      "Economic:  -1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "gen_max, gen_min = df[\"gender\"].max(), df[\"gender\"].min()\n",
    "sen_max, sen_min = df[\"sentiment\"].max(), df[\"sentiment\"].min()\n",
    "race_max, race_min = df[\"race\"].max(), df[\"race\"].min()\n",
    "relg_max, relg_min = df[\"religion\"].max(), df[\"religion\"].min()\n",
    "age_max, age_min = df[\"age\"].max(), df[\"age\"].min()\n",
    "eco_max, eco_min = df[\"economic\"].max(), df[\"economic\"].min()\n",
    "\n",
    "print(\"Gender: \",gen_min,gen_max)\n",
    "print(\"Sentiment: \",sen_min, sen_max)\n",
    "print(\"Race: \",race_min, race_max)\n",
    "print(\"Religion: \",relg_min, relg_max)\n",
    "print(\"Age: \",age_min, age_max)\n",
    "print(\"Economic: \",eco_min, eco_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gender</th>\n",
       "      <th>religion</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>economic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>-0.34613</td>\n",
       "      <td>0.0401356</td>\n",
       "      <td>-0.169161</td>\n",
       "      <td>0.175196</td>\n",
       "      <td>0.460523</td>\n",
       "      <td>-0.0589076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>-0.38412</td>\n",
       "      <td>-0.358522</td>\n",
       "      <td>0.698027</td>\n",
       "      <td>-0.679561</td>\n",
       "      <td>-0.359287</td>\n",
       "      <td>0.456002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "      <td>-0.253703</td>\n",
       "      <td>-0.695181</td>\n",
       "      <td>0.587224</td>\n",
       "      <td>-0.169453</td>\n",
       "      <td>-0.508056</td>\n",
       "      <td>0.438113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>-0.303191</td>\n",
       "      <td>-0.692863</td>\n",
       "      <td>0.364879</td>\n",
       "      <td>0.0609176</td>\n",
       "      <td>-0.243234</td>\n",
       "      <td>0.175101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>-0.238674</td>\n",
       "      <td>-0.0373804</td>\n",
       "      <td>0.619881</td>\n",
       "      <td>-0.367066</td>\n",
       "      <td>0.0390156</td>\n",
       "      <td>-0.00624037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word    gender   religion      race        age  sentiment    economic\n",
       "0    in  -0.34613  0.0401356 -0.169161   0.175196   0.460523  -0.0589076\n",
       "1   for  -0.38412  -0.358522  0.698027  -0.679561  -0.359287    0.456002\n",
       "2  that -0.253703  -0.695181  0.587224  -0.169453  -0.508056    0.438113\n",
       "3    is -0.303191  -0.692863  0.364879  0.0609176  -0.243234    0.175101\n",
       "4    on -0.238674 -0.0373804  0.619881  -0.367066  0.0390156 -0.00624037"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gender</th>\n",
       "      <th>religion</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>economic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50171</td>\n",
       "      <td>50171.0</td>\n",
       "      <td>50171.0</td>\n",
       "      <td>50171.0</td>\n",
       "      <td>50171.0</td>\n",
       "      <td>50171.0</td>\n",
       "      <td>50171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>50171</td>\n",
       "      <td>50126.0</td>\n",
       "      <td>50132.0</td>\n",
       "      <td>50124.0</td>\n",
       "      <td>50111.0</td>\n",
       "      <td>50146.0</td>\n",
       "      <td>50137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>curatorial</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word   gender  religion     race      age  sentiment  economic\n",
       "count        50171  50171.0   50171.0  50171.0  50171.0    50171.0   50171.0\n",
       "unique       50171  50126.0   50132.0  50124.0  50111.0    50146.0   50137.0\n",
       "top     curatorial     -0.0       0.0      0.0     -0.0       -0.0      -0.0\n",
       "freq             1     46.0      40.0     48.0     61.0       26.0      35.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50171, 7)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default option: min-max Normalization, _percentile option: percentile feature scaling\n",
    "\n",
    "#df.to_csv(\"../data/word2vec_50k.csv\", encoding='utf-8', index=False)\n",
    "df.to_csv(\"../data/word2vec_50k_percentile.csv\", encoding='utf-8', index=False)\n",
    "#df.to_csv(\"../data/glove_50k.csv\", encoding='utf-8', index=False)\n",
    "#df.to_csv(\"../data/glove_50k_percentile.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8128      0.344\n",
       "62       0.3336\n",
       "42430    0.3316\n",
       "57        0.312\n",
       "16295    0.3069\n",
       "          ...  \n",
       "35457    0.0001\n",
       "34752    0.0001\n",
       "32733    0.0001\n",
       "34231    0.0001\n",
       "25589    0.0001\n",
       "Name: gender, Length: 20221, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#v = [0.90, 0.87, 0.87, 0.76, 0.60, 0.32, 0.32, 0.32, 0.1, 0.05]\n",
    "values = df.loc[df[\"gender\"]>0][\"gender\"].sort_values(ascending=False, inplace=False)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100.0\n",
      "1 90.0\n",
      "3 70.0\n",
      "4 60.0\n",
      "5 50.0\n",
      "8 20.0\n",
      "9 10.0\n"
     ]
    }
   ],
   "source": [
    "percentile = []\n",
    "N = len(values)\n",
    "for i, val in enumerate(values):\n",
    "    if val==values[i-1]:\n",
    "        percentile.append(percentile[i-1])\n",
    "        continue\n",
    "    p = (N-i)/N*100\n",
    "    print(i,p)\n",
    "    percentile.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0, 90.0, 90.0, 70.0, 60.0, 50.0, 50.0, 50.0, 20.0, 10.0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8128      0.344\n",
       "62       0.3336\n",
       "42430    0.3316\n",
       "57        0.312\n",
       "16295    0.3069\n",
       "          ...  \n",
       "35457    0.0001\n",
       "34752    0.0001\n",
       "32733    0.0001\n",
       "34231    0.0001\n",
       "25589    0.0001\n",
       "Name: gender, Length: 20221, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"gender\"]>0][\"gender\"].sort_values(ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>gender</th>\n",
       "      <th>religion</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>-0.0391</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>0.0433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>-0.0491</td>\n",
       "      <td>-0.0273</td>\n",
       "      <td>-0.0058</td>\n",
       "      <td>-0.0341</td>\n",
       "      <td>-0.0399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that</td>\n",
       "      <td>-0.0621</td>\n",
       "      <td>-0.0591</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>-0.0792</td>\n",
       "      <td>-0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>-0.0432</td>\n",
       "      <td>-0.0588</td>\n",
       "      <td>-0.0449</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>-0.0266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>-0.0459</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>-0.0537</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50036</th>\n",
       "      <td>salaam</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>-0.1961</td>\n",
       "      <td>-0.1378</td>\n",
       "      <td>-0.1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50037</th>\n",
       "      <td>sunni</td>\n",
       "      <td>-0.0334</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>-0.1787</td>\n",
       "      <td>-0.1393</td>\n",
       "      <td>-0.0103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50038</th>\n",
       "      <td>koran</td>\n",
       "      <td>-0.0474</td>\n",
       "      <td>0.1698</td>\n",
       "      <td>-0.0362</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50039</th>\n",
       "      <td>shiite</td>\n",
       "      <td>-0.0162</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>-0.1113</td>\n",
       "      <td>-0.1006</td>\n",
       "      <td>0.1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50040</th>\n",
       "      <td>muhammad</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>-0.0655</td>\n",
       "      <td>-0.0794</td>\n",
       "      <td>0.0423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50041 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  gender religion    race     age sentiment\n",
       "0            in -0.0391   0.0022  0.0182 -0.0031    0.0433\n",
       "1           for -0.0491  -0.0273 -0.0058 -0.0341   -0.0399\n",
       "2          that -0.0621  -0.0591  0.0078 -0.0792   -0.0582\n",
       "3            is -0.0432  -0.0588 -0.0449  0.0088   -0.0266\n",
       "4            on -0.0459  -0.0029  0.0526 -0.0537    0.0032\n",
       "...         ...     ...      ...     ...     ...       ...\n",
       "50036    salaam  -0.005   0.2614 -0.1961 -0.1378   -0.1366\n",
       "50037     sunni -0.0334   0.2043 -0.1787 -0.1393   -0.0103\n",
       "50038     koran -0.0474   0.1698 -0.0362  -0.106    0.1036\n",
       "50039    shiite -0.0162   0.2177 -0.1113 -0.1006    0.1197\n",
       "50040  muhammad -0.0063   0.2415 -0.0655 -0.0794    0.0423\n",
       "\n",
       "[50041 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if col==\"word\":\n",
    "        continue\n",
    "    values = df.loc[df[col]>0][col].sort_values(ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of bias scores\n",
    "'''\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"gender\"]>0:\n",
    "        df.at[index, \"gender\"] = row[\"gender\"]/gen_max\n",
    "    else:\n",
    "        df.at[index, \"gender\"] = -1*row[\"gender\"]/gen_min\n",
    "        \n",
    "    if row[\"race\"]>0:\n",
    "        df.at[index, \"race\"] = row[\"race\"]/race_max\n",
    "    else:\n",
    "        df.at[index, \"race\"] = -1*row[\"race\"]/race_min\n",
    "    \n",
    "    if row[\"sentiment\"]>0:\n",
    "        df.at[index, \"sentiment\"] = row[\"sentiment\"]/sen_max\n",
    "    else:\n",
    "        df.at[index, \"sentiment\"] = -1*row[\"sentiment\"]/sen_min\n",
    "        \n",
    "    if row[\"religion\"]>0:\n",
    "        df.at[index, \"religion\"] = row[\"religion\"]/relg_max\n",
    "    else:\n",
    "        df.at[index, \"religion\"] = -1*row[\"religion\"]/relg_min\n",
    "    \n",
    "    if row[\"age\"]>0:\n",
    "        df.at[index, \"age\"] = row[\"age\"]/age_max\n",
    "    else:\n",
    "        df.at[index, \"age\"] = -1*row[\"age\"]/age_min  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
